{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-objective acquisition functions\n",
    "> A comparison of multi-objective acquisition functions in Bayesian optimization\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [Bayesian optimization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian optimization is a sample-efficient method for solving $\\min_{x \\in \\mathcal{X}} f(x)$ where $f$ is a black-box function whose evaluations are expensive and possibly noisy.\n",
    "\n",
    "When $f$ is vector-valued, i.e. there are multiple outputs that we care to minimize, there is in general no single optimal point.\n",
    "Instead we have a set of optimal compromises (the Pareto front), where for each point we cannot improve any one output without worsening at least one other output.\n",
    "\n",
    "There are two approaches for dealing with multiple objectives in the context of Bayesian optimization: \n",
    "1) Use a multi-objective scalarization together with a single-objective acquisition \n",
    "2) Use a multi-objective acquistion that aims for improving the knowledge of the Pareto front.\n",
    "\n",
    "Regarding 1. the same scalarizations as in multi-objective optimization may be applied. An overview of scalarization methods in the context of Bayesian optimization is given in [Chugh 2019]\n",
    "\n",
    "Regarding 2. there is a growing list of multi-objective acquistions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected hypervolume improvement\n",
    "Expected hypervolume improvement (EHVI), also known as S-metric-based expected improvement, is an extension of the expected improvement to multiple objectives. \n",
    "It's the expectation value of the improvement in hypervolume for a given candidate $x$ with respect to the existing data $\\mathcal{D}$.\n",
    "\n",
    "The first method to calculate EVHI was Monte Carlo integration [Emmerich 2005], however the accuracy of this method strongly depends on the number of MC samples.\n",
    "For the 2D case an exact methods was proposed in [Emmerich 2012] with complexity $O(n^3 \\log n)$, where $n$ is the number of non-dominated points in the data set.\n",
    "An exact method for >2D was proposed in [Cockuyt 2014] without an analysis of the complexity.\n",
    "[Hupkens 2015] introduced a method with complexity of $O(n^2)$ for 2D and $O(n^3)$ for 3D.\n",
    "Asymptotically optimal algorithms with $O(n \\log n)$ complexity were proposed in [Emmerich 2016] for the 2D case, and in [Yang 2017] for the 3D case.\n",
    "In [Yang 2019] this was extended to >4D and to the probability of improvement on the Pareto front.\n",
    "Codes are found [here](http://liacs.leidenuniv.nl/~csmoda/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Chugh (2019) Scalarizing Functions in Bayesian Multiobjective Optimization  \n",
    "  https://arxiv.org/abs/1904.05760\n",
    "* Emmerich (2005) Single- and Multi-objective Evolutionary Design Optimization Assisted by Gaussian Random Field Metamodels  \n",
    "  https://d-nb.info/998357294/34\n",
    "* Svenson+ (2016) Multiobjective optimization of expensive-to-evaluate deterministic computer simulator models  \n",
    "  https://www.sciencedirect.com/science/article/pii/S0167947315001991\n",
    "* Keane (2012) Statistical Improvement Criteria for Use in Multiobjective Design Optimization  \n",
    "  https://arc.aiaa.org/doi/abs/10.2514/1.16875?journalCode=aiaaj\n",
    "* Garrido-Merchan+ (2019) Predictive Entropy Search for Multi-objective Bayesian Optimization with Constraints  \n",
    "  https://www.sciencedirect.com/science/article/pii/S0925231219308525\n",
    "* Picheny (2015) Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction  \n",
    "  https://link.springer.com/article/10.1007/s11222-014-9477-x\n",
    "* Bradford (2018) Efficient multiobjective optimization employing Gaussian processes, spectral sampling and a genetic algorithm  \n",
    "  https://doi.org/10.1007/s10898-018-0609-2\n",
    "* Deutz (2019) Expected R2 Indicator Improvement as an Infill Criterion in Bi-objective Bayesian Optimization  \n",
    "  https://link.springer.com/chapter/10.1007/978-3-030-12598-1_29\n",
    "* Zachary+ (2019) Assessing the Frontier: Active Learning, Model Accuracy, and Multi-objective Materials Discovery and Optimization  \n",
    "  https://arxiv.org/abs/1911.03224\n",
    "* Emmerich+ (2012) Hypervolume-based expected improvement: monotonicity properties and exact computation  \n",
    "  https://ieeexplore.ieee.org/abstract/document/5949880\n",
    "* Couckuyt+ (2014) Fast calculation of multiobjective probability of improvement and expected improvement criteria for Pareto optimization  \n",
    "  https://link.springer.com/article/10.1007/s10898-013-0118-2\n",
    "* Hupkens+ (2015) Faster exact algorithms for computing expected hypervolume improvement  \n",
    "  https://link.springer.com/chapter/10.1007/978-3-319-15892-1_5\n",
    "* Emmerich+ (2016) A multicriteria generalization of Bayesian global optimization  \n",
    "  https://link.springer.com/chapter/10.1007/978-3-319-29975-4_12\n",
    "* Yang+ (2017) Computing 3-D expected hypervolume improvement and related integrals in asymptotically optimal time  \n",
    "  https://link.springer.com/chapter/10.1007/978-3-319-54157-0_46\n",
    "* Yang+ (2019) Efficient computation of expected hypervolume improvement using box decomposition algorithms  \n",
    "  https://link.springer.com/article/10.1007/s10898-019-00798-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda80041dba7d8f4a8783e715fa435efec5",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}