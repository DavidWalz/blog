@generic{Shahriari2016,
   abstract = {—Big data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., rec-ommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involves many tunable config-uration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
   author = {Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P. Adams and Nando De Freitas},
   doi = {10.1109/JPROC.2015.2494218},
   issn = {00189219},
   journal = {Proceedings of the IEEE},
   keywords = {decision making,design of experiments,genomic medicine,optimization,response surface methodology,statistical learning},
   title = {Taking the human out of the loop: A review of Bayesian optimization},
   year = {2016},
}
@article{Swersky2013,
   abstract = {Bayesian optimization has recently been proposed as a framework for automati- cally tuning the hyperparameters of machine learning models and has been shown to yield state-of-the-art performance with impressive ease and efficiency. In this paper, we explore whether it is possible to transfer the knowledge gained from previous optimizations to new tasks in order to find optimal hyperparameter set- tings more efficiently. Our approach is based on extending multi-task Gaussian processes to the framework of Bayesian optimization. We show that this method significantly speeds up the optimization process when compared to the standard single-task approach. We further propose a straightforward extension of our al- gorithm in order to jointly minimize the average error across multiple tasks and demonstrate how this can be used to greatly speed up k-fold cross-validation. Lastly, we propose an adaptation of a recently developed acquisition function, en- tropy search, to the cost-sensitive, multi-task setting. We demonstrate the utility of this new acquisition function by leveraging a small dataset to explore hyper- parameter settings for a large dataset. Our algorithm dynamically chooses which dataset to query in order to yield the most information per unit cost.},
   author = {Kevin Swersky and Jasper Snoek and Ryan P. Adams},
   issn = {10495258},
   journal = {NIPS},
   title = {Multi-Task Bayesian Optimization},
   year = {2013},
}
@inproceedings{Springenberg2016,
   abstract = {© 2016 NIPS Foundation - All Rights Reserved. Bayesian optimization is a prominent method for optimizing expensive-to-evaluate black-box functions that is widely applied to tuning the hyperparameters of machine learning algorithms. Despite its successes, the prototypical Bayesian optimization approach - using Gaussian process models - does not scale well to either many hyperparameters or many function evaluations. Attacking this lack of scalability and flexibility is thus one of the key challenges of the field. We present a general approach for using flexible parametric models (neural networks) for Bayesian optimization, staying as close to a truly Bayesian treatment as possible. We obtain scalability through stochastic gradient Hamiltonian Monte Carlo, whose robustness we improve via a scale adaptation. Experiments including multi-task Bayesian optimization with 21 tasks, parallel optimization of deep neural networks and deep reinforcement learning show the power and flexibility of this approach.},
   author = {J.T. Springenberg and A. Klein and S. Falkner and F. Hutter},
   issn = {10495258},
   journal = {Advances in Neural Information Processing Systems},
   title = {Bayesian optimization with Robust Bayesian neural networks},
   year = {2016},
}
@book_section{Frazier2018,
   abstract = {Suppose we have a function f : X → R that we with to minimize on some domain X ⊆ X . That is, we wish to x * = arg min x∈X f (x). In numerical analysis, this problem is typically called (global) optimization and has been the subject of decades of study. We draw a distinction between global optimization, where we seek the absolute optimum in X, and local optimization, where we seek to a local optimum in the neighborhood of a given initial point x 0 . A common approach to optimization problems is to make some assumptions about f . For example, when the objective function f is known to be convex and the domain X is also convex, the problem is known as convex optimization and has been widely studied. Convex optimization is a common tool used across machine learning. If an exact functional form for f is not available (that is, f behaves as a " black box "), what can we do? Bayesian optimization proceeds by maintaining a probabilistic belief about f and designing a so-called acquisition function to determine where to evaluate the function next. Bayesian optimization is particularly well-suited to global optimization problems where f is an expensive black-box function; for example, evaluating f might require running an expensive simulation. Bayesian optimization has recently become popular for training expensive machine-learning models whose behavior depend in a complicated way on their parameters (e.g., convolutional neural networks). This is an example of the " AutoML " paradigm. Although not strictly required, Bayesian optimization almost always reasons about f by choosing an appropriate Gaussian process prior:},
   author = {Peter I. Frazier},
   doi = {10.1287/educ.2018.0188},
   journal = {Recent Advances in Optimization and Modeling of Contemporary Problems},
   title = {Bayesian Optimization},
   year = {2018},
}
@book_section{Laumanns2002,
   abstract = {In recent years, several researchers have concentrated on using probabilistic models in evolutionary algorithms. These Estimation Distribution Algorithms (EDA) incorporate methods for automated learning of correlations between variables of the encoded solutions. The process of sampling new individuals from a probabilistic model respects these mutual dependencies such that disruption of important building blocks is avoided, in comparison with classical recombination operators. The goal of this paper is to investigate the usefulness of this concept in multi-objective optimization, where the aim is to approximate the set of Pareto-optimal solutions. We integrate the model building and sampling techniques of a special EDA called Bayesian Optimization Algorithm, based on binary decision trees, into an evolutionary multi-objective op-timizer using a special selection scheme. The behavior of the resulting Bayesian Multi-objective Optimization Algorithm (BMOA) is empirically investigated on the multi-objective knapsack problem.},
   author = {Marco Laumanns and Jiri Ocenasek},
   doi = {10.1007/3-540-45712-7_29},
   title = {Bayesian Optimization Algorithms for Multi-objective Optimization},
   year = {2002},
}
@article{Ueno2016,
   abstract = {In many subfields of chemistry and physics, numerous attempts have been made to accelerate scientific discovery using data-driven experimental design algorithms. Among them, Bayesian optimization has been proven to be an effective tool. A standard implementation (e.g., scikit-learn), however, can accommodate only small training data. We designed an efficient protocol for Bayesian optimization that employs Thompson sampling, random feature maps, one-rank Cholesky update and automatic hyperparameter tuning, and implemented it as an open-source python library called COMBO (COMmon Bayesian Optimization library). Promising results using COMBO to determine the atomic structure of a crystalline interface are presented. COMBO is available at https://github.com/tsudalab/combo.},
   author = {Tsuyoshi Ueno and Trevor David Rhone and Zhufeng Hou and Teruyasu Mizoguchi and Koji Tsuda},
   doi = {10.1016/j.md.2016.04.001},
   issn = {23529245},
   journal = {Materials Discovery},
   keywords = {Bayesian optimization,Global optimization,Materials design,Python library},
   title = {COMBO: An efficient Bayesian optimization library for materials science},
   year = {2016},
}
@article{Bergstra2013,
   abstract = {Sequential model-based optimization (also known as Bayesian op- timization) is one of the most efficient methods (per function evaluation) of function minimization. This efficiency makes it appropriate for optimizing the hyperparameters of machine learning algorithms that are slow to train. The Hyperopt library provides algorithms and parallelization infrastructure for per- forming hyperparameter optimization (model selection) in Python. This paper presents an introductory tutorial on the usage of the Hyperopt library, including the description of search spaces, minimization (in serial and parallel), and the analysis of the results collected in the course of minimization. The paper closes with some discussion of ongoing and future work.},
   author = {James Bergstra and Dan Yamins and David D Cox},
   journal = {12th PYTHON IN SCIENCE CONF. (SCIPY 2013)},
   title = {Hyperopt: A python library for optimizing the hyperparameters of machine learning algorithms},
   url = {http://www.mendeley.com/research/hyperopt-python-library-optimizing-hyperparameters-machine-learning-algorithms},
   year = {2013},
}
@article{Akbari2018,
   abstract = {© 2018 Springer Science+Business Media, LLC, part of Springer Nature The presented study deals with the scalarization techniques for solving multiobjective optimization problems. The Pascoletti–Serafini scalarization technique is considered, and it is attempted to sidestep two weaknesses of this method, namely the inflexibility of the constraints and the difficulties of checking proper efficiency. To this end, two modifications for the Pascoletti–Serafini scalarization technique are proposed. First, by including surplus variables in the constraints and penalizing the violations in the objective function, the inflexibility of the constraints is resolved. Moreover, by including slack variables in the constraints, easy-to-check statements on proper efficiency are obtained. Thereafter, the two proposed modifications are combined to obtain the revised Pascoletti–Serafini scalarization method. Theorems are provided on the relation of (weakly, properly) efficient solutions of the multiobjective optimization problem and optimal solutions of the proposed scalarized problems. All the provided results are established with no convexity assumption. Moreover, the capability of the proposed approaches is demonstrated through numerical examples.},
   author = {Fereshteh Akbari and Mehrdad Ghaznavi and Esmaile Khorram},
   doi = {10.1007/s10957-018-1289-2},
   issn = {15732878},
   issue = {2},
   journal = {Journal of Optimization Theory and Applications},
   keywords = {Multiobjective programming,Pascoletti–Serafini method,Properly efficient solution,Scalarization technique},
   month = {8},
   pages = {560-590},
   publisher = {Springer New York LLC},
   title = {A Revised Pascoletti–Serafini Scalarization Method for Multiobjective Optimization Problems},
   volume = {178},
   year = {2018},
}
@article{Abdolshah2019,
   abstract = {We present a Bayesian multi-objective optimisation algorithm that allows the user to express preference-order constraints on the objectives of the type `objective A is more important than objective B'. Rather than attempting to find a representative subset of the complete Pareto front, our algorithm searches for and returns only those Pareto-optimal points that satisfy these constraints. We formulate a new acquisition function based on expected improvement in dominated hypervolume (EHI) to ensure that the subset of Pareto front satisfying the constraints is thoroughly explored. The hypervolume calculation only includes those points that satisfy the preference-order constraints, where the probability of a point satisfying the constraints is calculated from a gradient Gaussian Process model. We demonstrate our algorithm on both synthetic and real-world problems.},
   author = {Majid Abdolshah and Alistair Shilton and Santu Rana and Sunil Gupta and Svetha Venkatesh},
   month = {2},
   title = {Multi-objective Bayesian optimisation with preferences over objectives},
   url = {http://arxiv.org/abs/1902.04228},
   year = {2019},
}
@article{Amara2015,
   abstract = {Copyright © 2015 WILEY-VCH Verlag GmbH  &  Co. KGaA, Weinheim. A self-optimizing approach is used as a tool for targeting known and unknown materials in the continuous reaction of aniline, dimethyl carbonate (DMC) and tetrahydrofuran (THF) in supercritical CO<inf>2</inf> on γ-Al<inf>2</inf>O<inf>3</inf>. The study led to the formation of methylated anilines or carbamate derivatives and unusual addition products with THF including pyrrolidines and N-alkylated anilines. The identification of these products leads to the development of a plausible mechanism for the reactions. The system not only demonstrates a high flexibility that the self-optimization approach provides, including the ability to optimize for a variety of products by using a single catalyst, but also the ability to discover unexpected and original synthetic reactions. Self-optimizing continuous-flow reactors have been used to investigate the reaction of aniline with THF and DMC. High-selectivity profiles were obtained for the synthesis of methylated anilines or N-phenylpyrrolidines. By combining the three components in a single reaction system, a tandem alkylation reactivity leading to diversely alkylated anilines was discovered.},
   author = {Zacharias Amara and Emilia S. Streng and Ryan A. Skilton and Jing Jin and Michael W. George and Martyn Poliakoff},
   doi = {10.1002/ejoc.201500980},
   issn = {10990690},
   issue = {28},
   journal = {European Journal of Organic Chemistry},
   keywords = {Acid-base catalysis,Alkylation,Aniline,Flow chemistry,Self-optimization,Supercritical fluids},
   month = {10},
   pages = {6141-6145},
   publisher = {Wiley-VCH Verlag},
   title = {Automated Serendipity with Self-Optimizing Continuous-Flow Reactors},
   volume = {2015},
   year = {2015},
}
@article{Haese2018,
   abstract = {In this work we introduce PHOENICS, a probabilistic global optimization algorithm combining ideas from Bayesian optimization with concepts from Bayesian kernel density estimation. We propose an inexpensive acquisition function balancing the explorative and exploitative behavior of the algorithm. This acquisition function enables intuitive sampling strategies for an efficient parallel search of global minima. The performance of PHOENICS is assessed via an exhaustive benchmark study on a set of 15 discrete, quasi-discrete and continuous multidimensional functions. Unlike optimization methods based on Gaussian processes (GP) and random forests (RF), we show that PHOENICS is less sensitive to the nature of the co-domain, and outperforms GP and RF optimizations. We illustrate the performance of PHOENICS on the Oregonator, a difficult case-study describing a complex chemical reaction network. We demonstrate that only PHOENICS was able to reproduce qualitatively and quantitatively the target dynamic behavior of this nonlinear reaction dynamics. We recommend PHOENICS for rapid optimization of scalar, possibly non-convex, black-box unknown objective functions.},
   author = {Florian Häse and Loïc M. Roch and Christoph Kreisbeck and Alán Aspuru-Guzik},
   month = {1},
   title = {PHOENICS: A universal deep Bayesian optimizer},
   url = {http://arxiv.org/abs/1801.01469},
   year = {2018},
}
@article{Haese2018b,
   abstract = {Chimera enables multi-target optimization for experimentation or expensive computations, where evaluations are the limiting factor. Finding the ideal conditions satisfying multiple pre-defined targets simultaneously is a challenging decision-making process, which impacts science, engineering, and economics. Additional complexity arises for tasks involving experimentation or expensive computations, as the number of evaluated conditions must be kept low. We propose Chimera as a general purpose achievement scalarizing function for multi-target optimization where evaluations are the limiting factor. Chimera combines concepts of a priori scalarizing with lexicographic approaches and is applicable to any set of n unknown objectives. Importantly, it does not require detailed prior knowledge about individual objectives. The performance of Chimera is demonstrated on several well-established analytic multi-objective benchmark sets using different single-objective optimization algorithms. We further illustrate the applicability and performance of Chimera with two practical examples: (i) the auto-calibration of a virtual robotic sampling sequence for direct-injection, and (ii) the inverse-design of a four-pigment excitonic system for an efficient energy transport. The results indicate that Chimera enables a wide class of optimization algorithms to rapidly find ideal conditions. Additionally, the presented applications highlight the interpretability of Chimera to corroborate design choices for tailoring system parameters. },
   author = {Florian Häse and Loïc M. Roch and Alán Aspuru-Guzik},
   doi = {10.1039/c8sc02239a},
   issn = {20416539},
   issue = {39},
   journal = {Chemical Science},
   pages = {7642-7655},
   publisher = {Royal Society of Chemistry},
   title = {Chimera: Enabling hierarchy based multi-objective optimization for self-driving laboratories},
   volume = {9},
   year = {2018},
}
@article{Bortz2018,
   abstract = {The identification of a promising region in design space where strategies to obtain an optimal experimental design can be applied is crucial in practical applications. In this contribution, starting from a model adjusted to previously conducted experiments, a computationally efficient multicriteria optimization scheme is used to identify the Pareto boundary, where minimization of the prediction errors of the objective functions is included as additional objective. This guarantees that best compromises are found between the process-relevant objectives, like cost and quality criteria, while simultaneously quantifying the trade-off between those objectives and their prediction errors. In a real-time navigation procedure, this allows to narrow down the most promising region in design space, where then strategies of model-based experimental design are applied. The entire workflow is illustrated with an intuitive example which shows that an unacceptably high prediction error of Pareto points can be efficiently reduced by only a few additional experiments.},
   author = {M. Bortz and J. Höller and J. Schwientek and R. Böttcher and O. Hirth and N. Asprion},
   doi = {10.1016/j.ifacol.2018.04.003},
   issn = {24058963},
   issue = {2},
   journal = {IFAC-PapersOnLine},
   keywords = {Multiobjective optimizations,Optimal Experiment Design,Parameter estimation,Prediction error methods,Statistical design},
   month = {1},
   pages = {747-752},
   publisher = {Elsevier B.V.},
   title = {Experimental Design in a Multicriteria Optimization Context: An Adaptive Scheme},
   volume = {51},
   year = {2018},
}
@article{Bortz2017,
   abstract = {© 2017 American Chemical Society. Taking account of uncertain model parameters in simulation-based flowsheet optimization is crucial in order to quantify the reliability of the optimization results. Since chemical process design is a multicriteria optimization (MCO) task, methods to deal with uncertain Pareto boundaries are needed. The simplest of such methods consists of a sensitivity analysis of the Pareto boundary. In this work, it is shown how going beyond sensitivity analysis can yield favorable process designs not seen by sensitivity analysis alone. This is achieved by taking uncertainties into account by worst and best case Pareto boundaries or by considering the robustness of the Pareto boundary with respect to uncertain model parameters as additional objectives. In order to increase computational efficiency, for the first time, an adaptive scalarization approach is used to deal with uncertainties in MCO. The methods are illustrated by the calculation of a NQ curve of a distillation column.},
   author = {M. Bortz and J. Burger and E. Von Harbou and M. Klein and J. Schwientek and N. Asprion and R. Böttcher and K. H. Küfer and H. Hasse},
   doi = {10.1021/acs.iecr.7b02539},
   issn = {15205045},
   issue = {44},
   journal = {Industrial and Engineering Chemistry Research},
   month = {11},
   pages = {12672-12681},
   publisher = {American Chemical Society},
   title = {Efficient Approach for Calculating Pareto Boundaries under Uncertainties in Chemical Process Design},
   volume = {56},
   year = {2017},
}
@article{Hutchinson2017,
   abstract = {Despite increasing focus on data publication and discovery in materials science and related fields, the global view of materials data is highly sparse. This sparsity encourages training models on the union of multiple datasets, but simple unions can prove problematic as (ostensibly) equivalent properties may be measured or computed differently depending on the data source. These hidden contextual differences introduce irreducible errors into analyses, fundamentally limiting their accuracy. Transfer learning, where information from one dataset is used to inform a model on another, can be an effective tool for bridging sparse data while preserving the contextual differences in the underlying measurements. Here, we describe and compare three techniques for transfer learning: multi-task, difference, and explicit latent variable architectures. We show that difference architectures are most accurate in the multi-fidelity case of mixed DFT and experimental band gaps, while multi-task most improves classification performance of color with band gaps. For activation energies of steps in NO reduction, the explicit latent variable method is not only the most accurate, but also enjoys cancellation of errors in functions that depend on multiple tasks. These results motivate the publication of high quality materials datasets that encode transferable information, independent of industrial or academic interest in the particular labels, and encourage further development and application of transfer learning methods to materials informatics problems.},
   author = {Maxwell L. Hutchinson and Erin Antono and Brenna M. Gibbons and Sean Paradiso and Julia Ling and Bryce Meredig},
   month = {11},
   title = {Overcoming data scarcity with transfer learning},
   url = {http://arxiv.org/abs/1711.05099},
   year = {2017},
}
@article{Chugh2019,
   abstract = {Scalarizing functions have been widely used to convert a multiobjective optimization problem into a single objective optimization problem. However, their use in solving (computationally) expensive multi- and many-objective optimization problems in Bayesian multiobjective optimization is scarce. Scalarizing functions can play a crucial role on the quality and number of evaluations required when doing the optimization. In this article, we study and review 15 different scalarizing functions in the framework of Bayesian multiobjective optimization and build Gaussian process models (as surrogates, metamodels or emulators) on them. We use expected improvement as infill criterion (or acquisition function) to update the models. In particular, we compare different scalarizing functions and analyze their performance on several benchmark problems with different number of objectives to be optimized. The review and experiments on different functions provide useful insights when using and selecting a scalarizing function when using a Bayesian multiobjective optimization method.},
   author = {Tinkle Chugh},
   month = {4},
   title = {Scalarizing Functions in Bayesian Multiobjective Optimization},
   url = {http://arxiv.org/abs/1904.05760},
   year = {2019},
}
@article{Chen2017,
   abstract = {We propose and analyze two new MCMC sampling algorithms, the Vaidya walk and the John walk, for generating samples from the uniform distribution over a polytope. Both random walks are sampling algorithms derived from interior point methods. The former is based on volumetric-logarithmic barrier introduced by Vaidya whereas the latter uses John's ellipsoids. We show that the Vaidya walk mixes in significantly fewer steps than the logarithmic-barrier based Dikin walk studied in past work. For a polytope in $\mathbb\{R\}^d$ defined by $n >d$ linear constraints, we show that the mixing time from a warm start is bounded as $\mathcal\{O\}(n^\{0.5\}d^\{1.5\})$, compared to the $\mathcal\{O\}(nd)$ mixing time bound for the Dikin walk. The cost of each step of the Vaidya walk is of the same order as the Dikin walk, and at most twice as large in terms of constant pre-factors. For the John walk, we prove an $\mathcal\{O\}(d^\{2.5\}\cdot\log^4(n/d))$ bound on its mixing time and conjecture that an improved variant of it could achieve a mixing time of $\mathcal\{O\}(d^2\cdot\text\{polylog\}(n/d))$. Additionally, we propose variants of the Vaidya and John walks that mix in polynomial time from a deterministic starting point. We illustrate the speed-up of the Vaidya walk over the Dikin walk via several numerical examples.},
   author = {Yuansi Chen and Raaz Dwivedi and Martin J. Wainwright and Bin Yu},
   month = {10},
   title = {Fast MCMC sampling algorithms on polytopes},
   url = {http://arxiv.org/abs/1710.08165},
   year = {2017},
}
@article{Contal2013,
   abstract = {In this paper, we analyze a generic algorithm scheme for sequential global optimization using Gaussian processes. The upper bounds we derive on the cumulative regret for this generic algorithm improve by an exponential factor the previously known bounds for algorithms like GP-UCB. We also introduce the novel Gaussian Process Mutual Information algorithm (GP-MI), which significantly improves further these upper bounds for the cumulative regret. We confirm the efficiency of this algorithm on synthetic and real tasks against the natural competitor, GP-UCB, and also the Expected Improvement heuristic.},
   author = {Emile Contal and Vianney Perchet and Nicolas Vayatis},
   month = {11},
   title = {Gaussian Process Optimization with Mutual Information},
   url = {http://arxiv.org/abs/1311.4825},
   year = {2013},
}
@article{Bradford2018,
   abstract = {© 2018, Springer Science+Business Media, LLC, part of Springer Nature. Many engineering problems require the optimization of expensive, black-box functions involving multiple conflicting criteria, such that commonly used methods like multiobjective genetic algorithms are inadequate. To tackle this problem several algorithms have been developed using surrogates. However, these often have disadvantages such as the requirement of a priori knowledge of the output functions or exponentially scaling computational cost with respect to the number of objectives. In this paper a new algorithm is proposed, TSEMO, which uses Gaussian processes as surrogates. The Gaussian processes are sampled using spectral sampling techniques to make use of Thompson sampling in conjunction with the hypervolume quality indicator and NSGA-II to choose a new evaluation point at each iteration. The reference point required for the hypervolume calculation is estimated within TSEMO. Further, a simple extension was proposed to carry out batch-sequential design. TSEMO was compared to ParEGO, an expected hypervolume implementation, and NSGA-II on nine test problems with a budget of 150 function evaluations. Overall, TSEMO shows promising performance, while giving a simple algorithm without the requirement of a priori knowledge, reduced hypervolume calculations to approach linear scaling with respect to the number of objectives, the capacity to handle noise and lastly the ability for batch-sequential usage.},
   author = {Eric Bradford and Artur M. Schweidtmann and Alexei Lapkin},
   doi = {10.1007/s10898-018-0609-2},
   issn = {15732916},
   issue = {2},
   journal = {Journal of Global Optimization},
   keywords = {Bayesian optimization,Expensive-to-evaluate functions,Global optimization,Hypervolume,Kriging,Response surfaces},
   month = {6},
   pages = {407-438},
   publisher = {Springer New York LLC},
   title = {Efficient multiobjective optimization employing Gaussian processes, spectral sampling and a genetic algorithm},
   volume = {71},
   year = {2018},
}
@inproceedings{Azizzadenesheli2018,
   abstract = {We study reinforcement learning (RL) in high dimensional episodic Markov decision processes (MDP). We consider value-based RL when the optimal Q-value is a linear function of d-dimensional state-action feature representation. For instance, in deep-Q networks (DQN), the Q-value is a linear function of the feature representation layer (output layer). We propose two algorithms, one based on optimism, LinUCB, and another based on posterior sampling, LinPSRL. We guarantee frequentist and Bayesian regret upper bounds of O(d sqrt(T)) for these two algorithms, where T is the number of episodes. We extend these methods to deep RL and propose Bayesian deep Q-networks (BDQN), which uses an efficient Thompson sampling algorithm for high dimensional RL. We deploy the double DQN (DDQN) approach, and instead of learning the last layer of Q-network using linear regression, we use Bayesian linear regression, resulting in an approximated posterior over Q-function. This allows us to directly incorporate the uncertainty over the Q-function and deploy Thompson sampling on the learned posterior distribution resulting in efficient exploration/exploitation trade-off. We empirically study the behavior of BDQN on a wide range of Atari games. Since BDQN carries out more efficient exploration and exploitation, it is able to reach higher return substantially faster compared to DDQN.},
   author = {Kamyar Azizzadenesheli and Emma Brunskill and Animashree Anandkumar},
   doi = {10.1109/ITA.2018.8503252},
   isbn = {9781728101248},
   journal = {2018 Information Theory and Applications Workshop, ITA 2018},
   month = {10},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Efficient exploration through Bayesian deep Q-networks},
   year = {2018},
}
@article{Cortez2018,
   abstract = {A modular autonomous flow reactor combining monitoring technologies with a feedback algorithm is presented for the synthesis of the natural product carpanone. The autonomous self-optimizing system, controlled via MATLAB, was designed as a flexible platform enabling an adaptation of the experimental setup to the specificity of the chemical transformation to be optimized. The reaction monitoring uses either online high pressure liquid chromatography (HPLC) or in-line benchtop nuclear magnetic resonance (NMR) spectroscopy. The custom-made optimization algorithm derived from the Nelder–Mead and golden section search methods performs constrained optimizations of black-box functions in a multidimensional search domain, thereby assuming no a priori knowledge of the chemical reactions. This autonomous self-optimizing system allowed fast and efficient optimizations of the chemical steps leading to carpanone. This contribution is the first example of a multistep synthesis where all discrete steps were optimized wit...},
   author = {Daniel Cortés-Borda and Eric Wimmer and Boris Gouilleux and Elvina Barré and Nicolas Oger and Lubna Goulamaly and Louis Peault and Benoît Charrier and Charlotte Truchet and Patrick Giraudeau and Mireia Rodriguez-Zubiri and Erwan Le Grognec and François Xavier Felpin},
   doi = {10.1021/acs.joc.8b01821},
   issn = {15206904},
   issue = {23},
   journal = {Journal of Organic Chemistry},
   month = {12},
   pages = {14286-14289},
   publisher = {American Chemical Society},
   title = {An Autonomous Self-Optimizing Flow Reactor for the Synthesis of Natural Product Carpanone},
   volume = {83},
   year = {2018},
}
@article{Das2003,
   abstract = {This paper proposes an alternate method for finding several Pareto optimal points for a general nonlinear multicriteria optimization problem. Such points collectively capture the trade-off among the various conflicting objectives. It is proved that this method is independent of the relative scales of the functions and is successful in producing an evenly distributed set of points in the Pareto set given an evenly distributed set of parameters, a property which the popular method of minimizing weighted combinations of objective functions lacks. Further, this method can handle more than two objectives while retaining the computational efficiency of continuation-type algorithms. This is an improvement over continuation techniques for tracing the trade-off curve since continuation strategies cannot easily be extended to handle more than two objectives.},
   author = {Indraneel Das and J. E. Dennis},
   doi = {10.1137/s1052623496307510},
   issn = {1052-6234},
   issue = {3},
   journal = {SIAM Journal on Optimization},
   month = {6},
   pages = {631-657},
   publisher = {Society for Industrial & Applied Mathematics (SIAM)},
   title = {Normal-Boundary Intersection: A New Method for Generating the Pareto Surface in Nonlinear Multicriteria Optimization Problems},
   volume = {8},
   year = {2003},
}
@article{Dempe2015,
   abstract = {© 2015, Springer-Verlag Berlin Heidelberg. In multi-objective optimization, one considers optimization problems with more than one objective function, and in general these objectives conflict each other. As the solution set of a multi-objective problem is often rather large and contains points of no interest to the decision-maker, strategies are sought that reduce the size of the solution set. One such strategy is to combine several objectives with each other, i.e. by summing them up, before employing tools to solve the resulting multi-objective optimization problem. This approach can be used to reduce the dimensionality of the objective space as well as to discard certain unwanted solutions, especially the ‘extreme’ ones found by minimizing just one of the objectives given in the classical sense while disregarding all others. In this paper, we discuss in detail how the strategy of combining objectives linearly influences the set of optimal, i.e. efficient solutions.},
   author = {Stephan Dempe and Gabriele Eichfelder and Jörg Fliege},
   doi = {10.1007/s00186-015-0501-5},
   issn = {14325217},
   issue = {1},
   journal = {Mathematical Methods of Operations Research},
   keywords = {Efficient set,Multi-objective,Pareto optimal},
   month = {8},
   publisher = {Springer Verlag},
   title = {On the effects of combining objectives in multi-objective optimization},
   volume = {82},
   year = {2015},
}
@inproceedings{Emmerich2011,
   abstract = {The expected improvement (EI) is a well established criterion in Bayesian global optimization (BGO) and metamodel-assisted evolutionary computation, both applied in optimization with costly function evaluations. Recently, it has been adopted in different ways to multiobjective optimization. A promising approach to formulate the expected improvement in this context, is to base it on the hypervolume indicator. Given the Bayesian model of the optimization landscape, the EI in hypervolume computes the expected gain in attained hypervolume for a given input point. Although a formulation of this expected improvement is relatively straightforward, its computation and mathematical properties are still to be investigated. This paper will outline and derive an algorithm for the exact computation of the proposed hypervolume-based EI. Moreover, this paper establishes monotonicity properties of the expected improvement. In particular the effect of the predictive distribution's variance on the hypervolume-based EI and elementary properties of the EI landscape are studied. The monotonicity properties will reveal regions where Pareto front approximations can be improved as well as underexplored regions that are favored by the hypervolume-based expected improvement. A first numerical example is included that illustrates the behavior of the hypervolume-based EI in the multiobjective BGO framework. © 2011 IEEE.},
   author = {Michael T.M. Emmerich and André H. Deutz and Jan Willem Klinkenberg},
   doi = {10.1109/CEC.2011.5949880},
   isbn = {9781424478347},
   journal = {2011 IEEE Congress of Evolutionary Computation, CEC 2011},
   pages = {2147-2154},
   title = {Hypervolume-based expected improvement: Monotonicity properties and exact computation},
   year = {2011},
}
@inproceedings{Deutz2019,
   abstract = {In multi-objective Bayesian optimization, an infill criterion is an important part, as it is the indicator to evaluate how much good a new set of solutions is, compared to a Pareto-front approximation set. This paper presents a deterministic algorithm for computing the Ex- pected R2 Indicator for bi-objective problems and studies its use as an infill criterion in Bayesian Global Optimization. The R2-Indicator was introduced in 1998 by M. Hansen and A. Jaszkiewicz for performance as- sessment in multi-objective optimization and is more recently also used in indicator-based multi-criterion evolutionary algorithms (IBEAs). In Bayesian Global Optimization, we propose the Expected R2-indicator Improvement (ER2I) as an infill criterion. It is defined as the expected decrease of the R2 indicator by a point that is sampled from a predic- tive Gaussian distribution. The ER2I can also be used as a pre-selection criterion in surrogate-assisted IBEAs. It provides an alternative to the Expected Hypervolume-Indicator Improvement (EHVI) that requires a reference point, bounding the Pareto front from above. In contrast, the ER2I works with a utopian reference point that bounds the Pareto front from below. In addition, the ER2I supports preference modelling with utility functions and its computation time grows only linearly with the number of considered weight combinations. It is straightforward to ap- proximate the ER2I by Monte Carlo Integration, but so far a determin- istic algorithm to solve the non-linear integral remained unknown. We outline a deterministic algorithm for the computation of the bi-objective ER2I with Chebychev utility functions. Moreover, we study monotonic- ity properties of the ER2I w.r.t. parameters of the predictive distribution and numerical simulations demonstrate fast convergence to Pareto fronts of different shapes and the ability of the ER2I Bayesian optimization to fill gaps in the Pareto front approximation.},
   author = {André Deutz and Michael Emmerich and Kaifeng Yang},
   doi = {10.1007/978-3-030-12598-1_29},
   isbn = {9783030125974},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Chebychev utility function,Expected improvement,Multiobjective Bayesian optimization,R2 indicator,Surrogate models},
   pages = {359-370},
   publisher = {Springer Verlag},
   title = {The expected R2-indicator improvement for multi-objective bayesian optimization},
   volume = {11411 LNCS},
   year = {2019},
}
@generic{Fabry2016,
   abstract = {In this review the recent progress in the field of self-optimizing reactor systems for continuous flow chemistry is presented.In this review the recent progress in the field of self-optimizing reactor systems for continuous flow chemistry is presented. Particular focus is directed to the implementation of monitoring tools and realization of computer-controlled reaction optimizations without human interaction.},
   author = {D. C. Fabry and E. Sugiono and M. Rueping},
   doi = {10.1039/c5re00038f},
   issn = {20589883},
   issue = {2},
   journal = {Reaction Chemistry and Engineering},
   month = {4},
   pages = {129-133},
   publisher = {Royal Society of Chemistry},
   title = {Online monitoring and analysis for autonomous continuous flow self-optimizing reactor systems},
   volume = {1},
   year = {2016},
}
@article{Frazier2009,
   abstract = {We consider a Bayesian ranking and selection problem with independent normal rewards and a correlated multivariate normal belief on the mean values of these rewards. Because this formulation of the ranking and selection problem models dependence between alternatives' mean values, algorithms may use this dependence to perform efficiently even when the number of alternatives is very large. We propose a fully sequential sampling policy called the knowledge-gradient policy, which is provably optimal in some special cases and has bounded suboptimality in all others. We then demonstrate how this policy may be applied to efficiently maximize a continuous function on a continuous domain while constrained to a fixed number of noisy measurements. © 2009 Informs.},
   author = {Peter Frazier and Warren Powell and Savas Dayanik},
   doi = {10.1287/ijoc.1080.0314},
   issn = {10919856},
   issue = {4},
   journal = {INFORMS Journal on Computing},
   keywords = {Bayesian,Decision analysis: sequential,Simulation: design of experiments,Statistics},
   month = {9},
   pages = {599-613},
   title = {The knowledge-gradient policy for correlated normal beliefs},
   volume = {21},
   year = {2009},
}
@generic{Fabry2014,
   abstract = {This review provides an overview of recent developments in the area of continuous flow process optimization by employing self-optimizing reactor systems. Although only few reactor concepts have been realized to date, impressive progress has been made, which now allows fully automated reaction optimization without the need of human interactions.},
   author = {David C. Fabry and Erli Sugiono and Magnus Rueping},
   doi = {10.1002/ijch.201300080},
   issn = {18695868},
   issue = {4},
   journal = {Israel Journal of Chemistry},
   keywords = {Suzuki reaction,asymmetric reduction,cross-coupling,hydrogenation,microreactor},
   pages = {341-350},
   publisher = {Wiley-VCH Verlag},
   title = {Self-optimizing reactor systems: Algorithms, on-line analytics, setups, and strategies for accelerating continuous flow process optimization},
   volume = {54},
   year = {2014},
}
@article{Heese2019,
   abstract = {In complex simulation environments, certain parameter space regions may result in non-convergent or unphysical outcomes. All parameters can therefore be labeled with a binary class describing whether or not they lead to valid results. In general, it can be very difficult to determine feasible parameter regions, especially without previous knowledge. We propose a novel algorithm to explore such an unknown parameter space and improve its feasibility classification in an iterative way. Moreover, we include an additional optimization target in the algorithm to guide the exploration towards regions of interest and to improve the classification therein. In our method we make use of well-established concepts from the field of machine learning like kernel support vector machines and kernel ridge regression. From a comparison with a Kriging-based exploration approach based on recently published results we can show the advantages of our algorithm in a binary feasibility classification scenario with a discrete feasibility constraint violation. In this context, we also propose an improvement of the Kriging-based exploration approach. We apply our novel method to a fully realistic, industrially relevant chemical process simulation to demonstrate its practical usability and find a comparably good approximation of the data space topology from relatively few data points.},
   author = {Raoul Heese and Michał Walczak and Tobias Seidel and Norbert Asprion and Michael Bortz},
   doi = {10.1016/j.compchemeng.2019.01.007},
   issn = {00981354},
   journal = {Computers and Chemical Engineering},
   keywords = {Data exploration,Feasibility classification,Machine learning,Simulation,Supervised learning},
   month = {5},
   pages = {326-342},
   publisher = {Elsevier Ltd},
   title = {Optimized data exploration applied to the simulation of a chemical process},
   volume = {124},
   year = {2019},
}
@article{Hennig2011,
   abstract = {Contemporary global optimization algorithms are based on local measures of utility, rather than a probability measure over location and value of the optimum. They thus attempt to collect low function values, not to learn about the optimum. The reason for the absence of probabilistic global optimizers is that the corresponding inference problem is intractable in several ways. This paper develops desiderata for probabilistic optimization algorithms, then presents a concrete algorithm which addresses each of the computational intractabilities with a sequence of approximations and explicitly adresses the decision problem of maximizing information gain from each evaluation.},
   author = {Philipp Hennig and Christian J. Schuler},
   month = {12},
   title = {Entropy Search for Information-Efficient Global Optimization},
   url = {http://arxiv.org/abs/1112.1217},
   year = {2011},
}
@article{Hernandez2014,
   abstract = {We propose a novel information-theoretic approach for Bayesian optimization called Predictive Entropy Search (PES). At each iteration, PES selects the next evaluation point that maximizes the expected information gained with respect to the global maximum. PES codifies this intractable acquisition function in terms of the expected reduction in the differential entropy of the predictive distribution. This reformulation allows PES to obtain approximations that are both more accurate and efficient than other alternatives such as Entropy Search (ES). Furthermore, PES can easily perform a fully Bayesian treatment of the model hyperparameters while ES cannot. We evaluate PES in both synthetic and real-world applications, including optimization problems in machine learning, finance, biotechnology, and robotics. We show that the increased accuracy of PES leads to significant gains in optimization performance.},
   author = {José Miguel Hernández-Lobato and Matthew W. Hoffman and Zoubin Ghahramani},
   month = {6},
   title = {Predictive Entropy Search for Efficient Global Optimization of Black-box Functions},
   url = {http://arxiv.org/abs/1406.2541},
   year = {2014},
}
@article{Gonzalez2015,
   abstract = {We present GLASSES: Global optimisation with Look-Ahead through Stochastic Simulation and Expected-loss Search. The majority of global optimisation approaches in use are myopic, in only considering the impact of the next function value; the non-myopic approaches that do exist are able to consider only a handful of future evaluations. Our novel algorithm, GLASSES, permits the consideration of dozens of evaluations into the future. This is done by approximating the ideal look-ahead loss function, which is expensive to evaluate, by a cheaper alternative in which the future steps of the algorithm are simulated beforehand. An Expectation Propagation algorithm is used to compute the expected value of the loss.We show that the far-horizon planning thus enabled leads to substantive performance gains in empirical tests.},
   author = {Javier González and Michael Osborne and Neil D. Lawrence},
   month = {10},
   title = {GLASSES: Relieving The Myopia Of Bayesian Optimisation},
   url = {http://arxiv.org/abs/1510.06299},
   year = {2015},
}
@report{Hutter,
   abstract = {State-of-the-art algorithms for hard computational problems often expose many parameters that can be modified to improve empirical performance. However, manually exploring the resulting combinatorial space of parameter settings is tedious and tends to lead to unsatisfactory outcomes. Recently, automated approaches for solving this algorithm configuration problem have led to substantial improvements in the state of the art for solving various problems. One promising approach constructs explicit regression models to describe the dependence of target algorithm performance on parameter settings; however, this approach has so far been limited to the optimization of few numerical algorithm parameters on single instances. In this paper, we extend this paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances. We experimentally validate our new algorithm configuration procedure by optimizing a local search and a tree search solver for the propositional satisfiability problem (SAT), as well as the commercial mixed integer programming (MIP) solver CPLEX. In these experiments, our procedure yielded state-of-the-art performance, and in many cases outperformed the previous best configuration approach.},
   author = {Frank Hutter and Holger H Hoos and Kevin Leyton-Brown},
   title = {Sequential Model-Based Optimization for General Algorithm Configuration},
}
@article{Letham2019,
   abstract = {Randomized experiments are the gold standard for evaluating the effects of changes to real-world systems. Data in these tests may be difficult to collect and outcomes may have high variance, resulting in potentially large measurement error. Bayesian optimization is a promising technique for efficiently optimizing multiple continuous parameters, but existing approaches degrade in performance when the noise level is high, limiting its applicability to many randomized experiments. We derive an expression for expected improvement under greedy batch optimization with noisy observations and noisy constraints, and develop a quasi-Monte Carlo approximation that allows it to be efficiently optimized. Simulations with synthetic functions show that optimization performance on noisy, constrained problems outperforms existing methods. We further demonstrate the effectiveness of the method with two real-world experiments conducted at Facebook: optimizing a ranking system, and optimizing server compiler flags.},
   author = {Benjamin Letham and Brian Karrer and Guilherme Ottoni and Eytan Bakshy},
   doi = {10.1214/18-BA1110},
   issn = {19316690},
   issue = {2},
   journal = {Bayesian Analysis},
   keywords = {Bayesian optimization,Quasi-Monte Carlo methods,Randomized experiments},
   pages = {495-519},
   publisher = {International Society for Bayesian Analysis},
   title = {Constrained Bayesian optimization with noisy experiments},
   volume = {14},
   year = {2019},
}
@article{Houben2015,
   abstract = {Self-optimization of chemical reactions enables faster optimization of reaction conditions or discovery of molecules with required target properties. The technology of self-optimization has been expanded to discovery of new process recipes for manufacture of complex functional products. A new machine-learning algorithm, specifically designed for multiobjective target optimization with an explicit aim to minimize the number of ?expensive? experiments, guides the discovery process. This ?black-box? approach assumes no a priori knowledge of chemical system and hence particularly suited to rapid development of processes to manufacture specialist low-volume, high-value products. The approach was demonstrated in discovery of process recipes for a semibatch emulsion copolymerization, targeting a specific particle size and full conversion.\nSelf-optimization of chemical reactions enables faster optimization of reaction conditions or discovery of molecules with required target properties. The technology of self-optimization has been expanded to discovery of new process recipes for manufacture of complex functional products. A new machine-learning algorithm, specifically designed for multiobjective target optimization with an explicit aim to minimize the number of ?expensive? experiments, guides the discovery process. This ?black-box? approach assumes no a priori knowledge of chemical system and hence particularly suited to rapid development of processes to manufacture specialist low-volume, high-value products. The approach was demonstrated in discovery of process recipes for a semibatch emulsion copolymerization, targeting a specific particle size and full conversion.},
   author = {Claudia Houben and Nicolai Peremezhney and Alexandr Zubov and Juraj Kosek and Alexei A. Lapkin},
   doi = {10.1021/acs.oprd.5b00210},
   issn = {1520586X},
   issue = {8},
   journal = {Organic Process Research and Development},
   month = {3},
   pages = {1049-1053},
   publisher = {American Chemical Society},
   title = {Closed-Loop Multitarget Optimization for Discovery of New Emulsion Polymerization Recipes},
   volume = {19},
   year = {2015},
}
@generic{Houben2015,
   abstract = {This paper presents the first overview of recent developments in techniques and methods that enable closed-loop optimization, also sometimes called 'self optimization', as well as discovery in different areas of molecular sciences. The closed-loop experimental platforms offer tremendous new opportunities by significantly increasing productivity, as well as enabling completely new types of experiments to be performed. Such experiments involve three main enabling technology areas: automated experimental systems, analytical instruments connected to automated chemoinformatics software and optimization or decision-making algorithms. We review the most exciting developments concerning robotic experiments, 3D printed lab-ware, experimental systems with multiple analytical instruments and advanced optimization algorithms based on machine learning approaches. A range of different chemical problems is described, which show the breadth of potential applications of this emerging experimental approach.},
   author = {Claudia Houben and Alexei A. Lapkin},
   doi = {10.1016/j.coche.2015.07.001},
   issn = {22113398},
   journal = {Current Opinion in Chemical Engineering},
   month = {7},
   pages = {1-7},
   publisher = {Elsevier Ltd},
   title = {Automatic discovery and optimization of chemical processes},
   volume = {9},
   year = {2015},
}
@report{Jones1998,
   abstract = {In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome.},
   author = {Donald R Jones and Matthias Schonlau and William J Welch},
   journal = {Journal of Global Optimization},
   keywords = {Bayesian global optimization,Kriging,Random function,Response surface,Stochastic process,Visualization},
   pages = {455-492},
   title = {Efficient Global Optimization of Expensive Black-Box Functions},
   volume = {13},
   year = {1998},
}
@article{Li2016,
   abstract = {Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select configurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration non-stochastic infinite-armed bandit problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems.},
   author = {Lisha Li and Kevin Jamieson and Giulia DeSalvo and Afshin Rostamizadeh and Ameet Talwalkar},
   month = {3},
   title = {Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization},
   url = {http://arxiv.org/abs/1603.06560},
   year = {2016},
}
@article{McMullen2010,
   abstract = {Set it and forget it: The combination of feedback control and continuous-flow operations in microreactors (see picture) enables online and fully automated reaction optimization. A Heck reaction demonstrates the potential for rapid multivariable reaction optimization while requiring a minimal amount of material. Optimal conditions are quickly scaled-up by a factor of 50. © 2010 Wiley-VCH Verlag GmbH & Co. KGaA.},
   author = {Jonathan P. McMullen and Matthew T. Stone and Stephen L. Buchwald and Klavs F. Jensen},
   doi = {10.1002/anie.201002590},
   issn = {14337851},
   issue = {39},
   journal = {Angewandte Chemie - International Edition},
   keywords = {Arenes,C-C coupling,Microreactors,Palladium,Synthetic methods},
   month = {9},
   pages = {7076-7080},
   title = {An integrated microreactor system for self-optimization of a heck reaction: From micro-to mesoscale flow systems},
   volume = {49},
   year = {2010},
}
@article{Mistry2018,
   abstract = {Decision trees usefully represent sparse, high dimensional and noisy data. Having learned a function from this data, we may want to thereafter integrate the function into a larger decision-making problem, e.g., for picking the best chemical process catalyst. We study a large-scale, industrially-relevant mixed-integer nonlinear nonconvex optimization problem involving both gradient-boosted trees and penalty functions mitigating risk. This mixed-integer optimization problem with convex penalty terms broadly applies to optimizing pre-trained regression tree models. Decision makers may wish to optimize discrete models to repurpose legacy predictive models, or they may wish to optimize a discrete model that particularly well-represents a data set. We develop several heuristic methods to find feasible solutions, and an exact, branch-and-bound algorithm leveraging structural properties of the gradient-boosted trees and penalty functions. We computationally test our methods on concrete mixture design instance and a chemical catalysis industrial instance.},
   author = {Miten Mistry and Dimitrios Letsios and Gerhard Krennrich and Robert M. Lee and Ruth Misener},
   month = {3},
   title = {Mixed-Integer Convex Nonlinear Optimization with Gradient-Boosted Trees Embedded},
   url = {http://arxiv.org/abs/1803.00952},
   year = {2018},
}
@article{Marmin2016,
   abstract = {We deal with the efficient parallelization of Bayesian global optimization algorithms, and more specifically of those based on the expected improvement criterion and its variants. A closed form formula relying on multivariate Gaussian cumulative distribution functions is established for a generalized version of the multipoint expected improvement criterion. In turn, the latter relies on intermediate results that could be of independent interest concerning moments of truncated Gaussian vectors. The obtained expansion of the criterion enables studying its differentiability with respect to point batches and calculating the corresponding gradient in closed form. Furthermore , we derive fast numerical approximations of this gradient and propose efficient batch optimization strategies. Numerical experiments illustrate that the proposed approaches enable computational savings of between one and two order of magnitudes, hence enabling derivative-based batch-sequential acquisition function maximization to become a practically implementable and efficient standard.},
   author = {Sébastien Marmin and Clément Chevalier and David Ginsbourger},
   month = {9},
   title = {Efficient batch-sequential Bayesian optimization with moments of truncated Gaussian vectors},
   url = {http://arxiv.org/abs/1609.02700},
   year = {2016},
}
@article{Olofsson2019,
   abstract = {Tissue engineering and regenerative medicine looks at improving or restoring biological tissue function in humans and animals. We consider optimising neotissue growth in a three-dimensional scaffold during dynamic perfusion bioreactor culture, in the context of bone tissue engineering. The goal is to choose design variables that optimise two conflicting objectives: (i) maximising neotissue growth and (ii) minimising operating cost. We make novel extensions to Bayesian multi-objective optimisation in the case of one analytical objective function and one black-box, i.e. simulation-based, objective function. The analytical objective represents operating cost while the black-box neotissue growth objective comes from simulating a system of partial differential equations. The resulting multi-objective optimisation method determines the trade-off in the variables between neotissue growth and operating cost. Our method outperforms the most common approach in literature, genetic algorithms, in terms of data efficiency, on both the tissue engineering example and standard test functions. The resulting method is highly applicable to real-world problems combining black-box models with easy-to-quantify objectives like cost. CCBY},
   author = {Simon Olofsson and Mohammad Mehrian and Roberto Calandra and Liesbet Geris and Marc Peter Deisenroth and Ruth Misener},
   doi = {10.1109/TBME.2018.2855404},
   issn = {15582531},
   issue = {3},
   journal = {IEEE Transactions on Biomedical Engineering},
   keywords = {Bayesian optimisation,black-box optimisation,multi-objective optimisation,tissue engineering},
   month = {3},
   pages = {727-739},
   publisher = {IEEE Computer Society},
   title = {Bayesian Multiobjective Optimisation with Mixed Analytical and Black-Box Functions: Application to Tissue Engineering},
   volume = {66},
   year = {2019},
}
@article{Noe2018,
   abstract = {Bayesian optimization (BO) is a popular algorithm for solving challenging optimization tasks. It is designed for problems where the objective function is expensive to evaluate, perhaps not available in exact form, without gradient information and possibly returning noisy values. Different versions of the algorithm vary in the choice of the acquisition function, which recommends the point to query the objective at next. Initially, researchers focused on improvement-based acquisitions, while recently the attention has shifted to more computationally expensive information-theoretical measures. In this paper we present two major contributions to the literature. First, we propose a new improvement-based acquisition function that recommends query points where the improvement is expected to be high with high confidence. The proposed algorithm is evaluated on a large set of benchmark functions from the global optimization literature, where it turns out to perform at least as well as current state-of-the-art acquisition functions, and often better. This suggests that it is a powerful default choice for BO. The novel policy is then compared to widely used global optimization solvers in order to confirm that BO methods reduce the computational costs of the optimization by keeping the number of function evaluations small. The second main contribution represents an application to precision medicine, where the interest lies in the estimation of parameters of a partial differential equations model of the human pulmonary blood circulation system. Once inferred, these parameters can help clinicians in diagnosing a patient with pulmonary hypertension without going through the standard invasive procedure of right heart catheterization, which can lead to side effects and complications (e.g. severe pain, internal bleeding, thrombosis).},
   author = {Umberto Noè and Dirk Husmeier},
   month = {8},
   title = {On a New Improvement-Based Acquisition Function for Bayesian Optimization},
   url = {http://arxiv.org/abs/1808.06918},
   year = {2018},
}
@article{Wager2014,
   abstract = {We study the variability of predictions made by bagged learners and random forests, and show how to estimate standard errors for these methods. Our work builds on variance estimates for bagging proposed by Efron (1992, 2013) that are based on the jackknife and the infinitesimal jackknife (IJ). In practice, bagged predictors are computed using a finite number B of bootstrap replicates, and working with a large B can be computationally expensive. Direct applications of jackknife and IJ estimators to bagging require B = Θ(n1.5) bootstrap replicates to converge, where n is the size of the training set. We propose improved versions that only require B = Θ(n) replicates. Moreover, we show that the IJ estimator requires 1.7 times less bootstrap replicates than the jackknife to achieve a given accuracy. Finally, we study the sampling distributions of the jackknife and IJ variance estimates themselves. We illustrate our findings with multiple experiments and simulation studies.},
   author = {Stefan Wager and Trevor Hastie and Bradley Efron},
   issn = {1532-4435},
   issue = {1},
   journal = {Journal of machine learning research : JMLR},
   month = {1},
   pages = {1625-1651},
   pmid = {25580094},
   title = {Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife.},
   volume = {15},
   url = {http://www.ncbi.nlm.nih.gov/pubmed/25580094 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4286302},
   year = {2014},
}
@article{Woods2017,
   abstract = {The design of an experiment can be always be considered at least implicitly Bayesian, with prior knowledge used informally to aid decisions such as the variables to be studied and the choice of a plausible relationship between the explanatory variables and measured responses. Bayesian methods allow uncertainty in these decisions to be incorporated into design selection through prior distributions that encapsulate information available from scientific knowledge or previous experimentation. Further, a design may be explicitly tailored to the aim of the experiment through a decision-theoretic approach using an appropriate loss function. We review the area of decision-theoretic Bayesian design, with particular emphasis on recent advances in computational methods. For many problems arising in industry and science, experiments result in a discrete response that is well described by a member of the class of generalised linear models. We describe how Gaussian process emulation, commonly used in computer experiments, can play an important role in facilitating Bayesian design for realistic problems. A main focus is the combination of Gaussian process regression to approximate the expected loss with cyclic descent (coordinate exchange) optimisation algorithms to allow optimal designs to be found for previously infeasible problems. We also present the first optimal design results for statistical models formed from dimensional analysis, a methodology widely employed in the engineering and physical sciences to produce parsimonious and interpretable models. Using the famous paper helicopter experiment, we show the potential for the combination of Bayesian design, generalised linear models and dimensional analysis to produce small but informative experiments.},
   author = {David C. Woods and Antony M. Overstall and Maria Adamou and Timothy W. Waite},
   doi = {10.1080/08982112.2016.1246045},
   issn = {15324222},
   issue = {1},
   journal = {Quality Engineering},
   keywords = {Computer experiments,D-optimality,Gaussian process models,high-dimensional design,nonlinear models,smoothing},
   month = {1},
   pages = {91-103},
   publisher = {Taylor and Francis Inc.},
   title = {Bayesian design of experiments for generalized linear models and dimensional analysis with industrial and scientific application},
   volume = {29},
   year = {2017},
}
@inproceedings{Wang2017,
   abstract = {We propose a simple but strong baseline for time series classification from scratch with deep neural networks. Our proposed baseline models are pure end-to-end without any heavy preprocessing on the raw data or feature crafting. The proposed Fully Convolutional Network (FCN) achieves premium performance to other state-of-the-art approaches and our exploration of the very deep neural networks with the ResNet structure is also competitive. The global average pooling in our convolutional model enables the exploitation of the Class Activation Map (CAM) to find out the contributing region in the raw data for the specific labels. Our models provides a simple choice for the real world application and a good starting point for the future research. An overall analysis is provided to discuss the generalization capability of our models, learned features, network structures and the classification semantics.},
   author = {Zhiguang Wang and Weizhong Yan and Tim Oates},
   doi = {10.1109/IJCNN.2017.7966039},
   isbn = {9781509061815},
   journal = {Proceedings of the International Joint Conference on Neural Networks},
   month = {6},
   pages = {1578-1585},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Time series classification from scratch with deep neural networks: A strong baseline},
   volume = {2017-May},
   year = {2017},
}
@article{Wang2015,
   abstract = {Recently, there has been rising interest in Bayesian optimization -- the optimization of an unknown function with assumptions usually expressed by a Gaussian Process (GP) prior. We study an optimization strategy that directly uses an estimate of the argmax of the function. This strategy offers both practical and theoretical advantages: no tradeoff parameter needs to be selected, and, moreover, we establish close connections to the popular GP-UCB and GP-PI strategies. Our approach can be understood as automatically and adaptively trading off exploration and exploitation in GP-UCB and GP-PI. We illustrate the effects of this adaptive tuning via bounds on the regret as well as an extensive empirical evaluation on robotics and vision tasks, demonstrating the robustness of this strategy for a range of performance criteria.},
   author = {Zi Wang and Bolei Zhou and Stefanie Jegelka},
   month = {10},
   title = {Optimization as Estimation with Gaussian Processes in Bandit Settings},
   url = {http://arxiv.org/abs/1510.06423},
   year = {2015},
}
@article{Wilson2018,
   abstract = {Bayesian optimization is a sample-efficient approach to global optimization that relies on theoretically motivated value heuristics (acquisition functions) to guide its search process. Fully maximizing acquisition functions produces the Bayes' decision rule, but this ideal is difficult to achieve since these functions are frequently non-trivial to optimize. This statement is especially true when evaluating queries in parallel, where acquisition functions are routinely non-convex, high-dimensional, and intractable. We first show that acquisition functions estimated via Monte Carlo integration are consistently amenable to gradient-based optimization. Subsequently, we identify a common family of acquisition functions, including EI and UCB, whose properties not only facilitate but justify use of greedy approaches for their maximization.},
   author = {James T. Wilson and Frank Hutter and Marc Peter Deisenroth},
   month = {5},
   title = {Maximizing acquisition functions for Bayesian optimization},
   url = {http://arxiv.org/abs/1805.10196},
   year = {2018},
}
@report{Roberts2012,
   abstract = {In this paper we offer a gentle introduction to Gaussian processes for timeseries data analysis. The conceptual framework of Bayesian modelling for timeseries data is discussed and the foundations of Bayesian non-parametric modelling presented for Gaussian processes. We discuss how domain knowledge influences design of the Gaussian process models and provide case examples to highlight the approaches.},
   author = {S Roberts and M Osborne and M Ebden and S Reece and N Gibson and & S Aigrain},
   keywords = {Bayesian modelling,Gaussian processes,timeseries analysis},
   title = {Gaussian Processes for Timeseries Modelling},
   year = {2012},
}
@article{Sagnol2015,
   abstract = {© Institute of Mathematical Statistics, 2015. Let the design of an experiment be represented by an s-dimensional vector w of weights with nonnegative components. Let the quality of w for the estimation of the parameters of the statistical model be measured by the criterion of D-optimality, defined as the Rath root of the determinant of the information matrix M(w) = Σsi= 1 ωi Ai ATi,where Ai,i = 1,...,s are known matrices with m rows. In this paper, we show that the criterion of D-optimality is second-order cone representable. As a result, the method of second-order cone programming can be used to compute an approximate D-optimal design with any system of linear constraints on the vector of weights. More importantly, the proposed characterization allows us to compute an exact D-optimal design, which is possible thanks to high-quality branch-and-cut solvers specialized to solve mixed integer second-order cone programming problems. our results extend to the case of the criterion of Dk-optimality, which measures the quality of w for the estimation of a linear parameter subsystem defined by a full-rank coefficient matrix K. We prove that some other widely used criteria are also second-order cone representable, for instance, the criteria of A-, Ak-, G- and I-optimality. We present several numerical examples demonstrating the efficiency and general applicability of the proposed method. We show that in many cases the mixed integer second-order cone programming approach allows us to find a provably optimal exact design, while the standard heuristics systematically miss the optimum.},
   author = {Guillaume Sagnol and Radoslav Harman},
   doi = {10.1214/15-AOS1339},
   issn = {00905364},
   issue = {5},
   journal = {Annals of Statistics},
   keywords = {D-criterion,Exact optimal designs,Mixed integer programming,Optimal experimental design,Second-order cone programming},
   month = {10},
   pages = {2198-2224},
   publisher = {Institute of Mathematical Statistics},
   title = {Computing exact D-optimal designs by mixed integer second-order cone programming},
   volume = {43},
   year = {2015},
}
@article{Redmon2018,
   abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/},
   author = {Joseph Redmon and Ali Farhadi},
   month = {4},
   title = {YOLOv3: An Incremental Improvement},
   url = {http://arxiv.org/abs/1804.02767},
   year = {2018},
}
@article{Sans2015,
   abstract = { A ‘dial-a-molecule’ platform for algorithm driven organic synthesis using real-time feedback, via in-line flow NMR spectroscopy, is demonstrated.  A configurable platform for synthetic chemistry incorporating an in-line benchtop NMR that is capable of monitoring and controlling organic reactions in real-time is presented. The platform is controlled via a modular LabView software control system for the hardware, NMR, data analysis and feedback optimization. Using this platform we report the real-time advanced structural characterization of reaction mixtures, including 19 F, 13 C, DEPT, 2D NMR spectroscopy (COSY, HSQC and 19 F-COSY) for the first time. Finally, the potential of this technique is demonstrated through the optimization of a catalytic organic reaction in real-time, showing its applicability to self-optimizing systems using criteria such as stereoselectivity, multi-nuclear measurements or 2D correlations. },
   author = {Victor Sans and Luzian Porwol and Vincenza Dragone and Leroy Cronin},
   doi = {10.1039/c4sc03075c},
   issn = {20416539},
   issue = {2},
   journal = {Chemical Science},
   month = {2},
   pages = {1258-1264},
   publisher = {Royal Society of Chemistry},
   title = {A self optimizing synthetic organic reactor system using real-time in-line NMR spectroscopy},
   volume = {6},
   year = {2015},
}
@article{Schweidtmann2018,
   abstract = {Automated development of chemical processes requires access to sophisticated algorithms for multi-objective optimization, since single-objective optimization fails to identify the trade-offs between conflicting performance criteria. Herein we report the implementation of a new multi-objective machine learning optimization algorithm for self-optimization, and demonstrate it in two exemplar chemical reactions performed in continuous flow. The algorithm successfully identified a set of optimal conditions corresponding to the trade-off curve (Pareto front) between environmental and economic objectives in both cases. Thus, it reveals the complete underlying trade-off and is not limited to one compromise as is the case in many other studies. The machine learning algorithm proved to be extremely data efficient, identifying the optimal conditions for the objectives in a lower number of experiments compared to single-objective optimizations. The complete underlying trade-off between multiple objectives is identified without arbitrary weighting factors, but via true multi-objective optimization.},
   author = {Artur M. Schweidtmann and Adam D. Clayton and Nicholas Holmes and Eric Bradford and Richard A. Bourne and Alexei A. Lapkin},
   doi = {10.1016/j.cej.2018.07.031},
   issn = {13858947},
   journal = {Chemical Engineering Journal},
   keywords = {Automated flow reactor,Environmental chemistry,Machine learning,Reaction engineering,Sustainable chemistry},
   month = {11},
   pages = {277-282},
   publisher = {Elsevier B.V.},
   title = {Machine learning meets continuous flow chemistry: Automated optimization towards the Pareto front of multiple objectives},
   volume = {352},
   year = {2018},
}
@report{Sculley2015,
   abstract = {Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.},
   author = {D Sculley and Gary Holt and Daniel Golovin and Eugene Davydov and Todd Phillips and Dietmar Ebner and Vinay Chaudhary and Michael Young and Jean-François Crespo and Dan Dennison},
   title = {Hidden Technical Debt in Machine Learning Systems},
   year = {2015},
}
@generic{Sans2016,
   abstract = {The integration of continuous-flow chemistry, in-line analytics and intelligent algorithms paves the way for autonomous platforms that rapidly close the gap between discovery and production. The employment of continuous-flow platforms for synthetic chemistry is becoming increasingly popular in research and industrial environments. Integrating analytics in-line enables obtaining a large amount of information in real-time about the reaction progress, catalytic activity and stability, etc. Furthermore, it is possible to influence the reaction progress and selectivity via manual or automated feedback optimisation, thus constituting a dial-a-molecule approach employing digital synthesis. This contribution gives an overview of the most significant contributions in the field to date. },
   author = {Victor Sans and Leroy Cronin},
   doi = {10.1039/c5cs00793c},
   issn = {14604744},
   issue = {8},
   journal = {Chemical Society Reviews},
   month = {4},
   pages = {2032-2043},
   publisher = {Royal Society of Chemistry},
   title = {Towards dial-a-molecule by integrating continuous flow, analytics and self-optimisation},
   volume = {45},
   year = {2016},
}
@inproceedings{Redmon2017,
   abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
   author = {Joseph Redmon and Ali Farhadi},
   doi = {10.1109/CVPR.2017.690},
   isbn = {9781538604571},
   journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
   month = {11},
   pages = {6517-6525},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {YOLO9000: Better, faster, stronger},
   volume = {2017-January},
   year = {2017},
}
@generic{Shahriari2016,
   abstract = {—Big data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., rec-ommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involves many tunable config-uration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
   author = {Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P. Adams and Nando De Freitas},
   doi = {10.1109/JPROC.2015.2494218},
   issn = {00189219},
   issue = {1},
   journal = {Proceedings of the IEEE},
   keywords = {decision making,design of experiments,genomic medicine,optimization,response surface methodology,statistical learning},
   month = {1},
   pages = {148-175},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Taking the human out of the loop: A review of Bayesian optimization},
   volume = {104},
   year = {2016},
}
@inproceedings{Smith2017,
   abstract = {It is known that the learning rate is the most important hyper-parameter to tune for training deep neural networks. This paper describes a new method for setting the learning rate, named cyclical learning rates, which practically eliminates the need to experimentally find the best values and schedule for the global learning rates. Instead of monotonically decreasing the learning rate, this method lets the learning rate cyclically vary between reasonable boundary values. Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations. This paper also describes a simple way to estimate "reasonable bounds" -- linearly increasing the learning rate of the network for a few epochs. In addition, cyclical learning rates are demonstrated on the CIFAR-10 and CIFAR-100 datasets with ResNets, Stochastic Depth networks, and DenseNets, and the ImageNet dataset with the AlexNet and GoogLeNet architectures. These are practical tools for everyone who trains neural networks.},
   author = {Leslie N. Smith},
   doi = {10.1109/WACV.2017.58},
   isbn = {9781509048229},
   journal = {Proceedings - 2017 IEEE Winter Conference on Applications of Computer Vision, WACV 2017},
   month = {5},
   pages = {464-472},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Cyclical learning rates for training neural networks},
   year = {2017},
}
@article{Srinivas2009,
   abstract = {Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.},
   author = {Niranjan Srinivas and Andreas Krause and Sham M. Kakade and Matthias Seeger},
   doi = {10.1109/TIT.2011.2182033},
   month = {12},
   title = {Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design},
   url = {http://arxiv.org/abs/0912.3995 http://dx.doi.org/10.1109/TIT.2011.2182033},
   year = {2009},
}
@article{Shahriari2014,
   abstract = {Bayesian optimization is a sample-efficient method for black-box global optimization. How- ever, the performance of a Bayesian optimization method very much depends on its exploration strategy, i.e. the choice of acquisition function, and it is not clear a priori which choice will result in superior performance. While portfolio methods provide an effective, principled way of combining a collection of acquisition functions, they are often based on measures of past performance which can be misleading. To address this issue, we introduce the Entropy Search Portfolio (ESP): a novel approach to portfolio construction which is motivated by information theoretic considerations. We show that ESP outperforms existing portfolio methods on several real and synthetic problems, including geostatistical datasets and simulated control tasks. We not only show that ESP is able to offer performance as good as the best, but unknown, acquisition function, but surprisingly it often gives better performance. Finally, over a wide range of conditions we find that ESP is robust to the inclusion of poor acquisition functions.},
   author = {Bobak Shahriari and Ziyu Wang and Matthew W. Hoffman and Alexandre Bouchard-Côté and Nando de Freitas},
   month = {6},
   title = {An Entropy Search Portfolio for Bayesian Optimization},
   url = {http://arxiv.org/abs/1406.4625},
   year = {2014},
}
@article{Knowles2006,
   abstract = { This paper concerns multiobjective optimization in scenarios where each solution evaluation is financially and/or temporally expensive. We make use of nine relatively low-dimensional, nonpathological, real-valued functions, such as arise in many applications, and assess the performance of two algorithms after just 100 and 250 (or 260) function evaluations. The results show that NSGA-II, a popular multiobjective evolutionary algorithm, performs well compared with random search, even within the restricted number of evaluations used. A significantly better performance (particularly, in the worst case) is, however, achieved on our test set by an algorithm proposed herein-ParEGO-which is an extension of the single-objective efficient global optimization (EGO) algorithm of Jones et al. ParEGO uses a design-of-experiments inspired initialization procedure and learns a Gaussian processes model of the search landscape, which is updated after every function evaluation. Overall, ParEGO exhibits a promising performance for multiobjective optimization problems where evaluations are expensive or otherwise restricted in number.},
   author = {Joshua Knowles},
   doi = {10.1109/TEVC.2005.851274},
   issn = {1089778X},
   issue = {1},
   journal = {IEEE Transactions on Evolutionary Computation},
   keywords = {Design and analysis of computer experiments (DACE),Efficient global optimization (EGO),Expensive black-box functions,Kriging,Landscape approximation,Nondominated sorting genetic algorithm II (NSGA-II),Pareto optima,Performance assessment,Response surfaces,Test suites},
   month = {2},
   pages = {50-66},
   title = {ParEGO: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems},
   volume = {10},
   year = {2006},
}
@book_section{Coello2018,
   abstract = {Using some real world examples I illustrate the important role of multiobjective optimization in decision making and its interface with preference handling. I explain what optimization in the presence of multiple objectives means and discuss some of the most common methods of solving multiobjective optimization problems using transformations to single objective optimisation problems. Finally, I address linear and combinatorial optimization problems with multiple objectives and summarize techniques for solving them. Throughout the article, I refer to the real world examples introduced at the beginning.},
   author = {Carlos A. Coello Coello},
   doi = {10.1007/978-3-319-07124-4_17},
   isbn = {9783319071244},
   journal = {Handbook of Heuristics},
   keywords = {Multi-objective optimization,evolutionary algorithms,metaheuristics,optimization},
   month = {8},
   pages = {177-204},
   publisher = {Springer International Publishing},
   title = {Multi-objective optimization},
   volume = {1-2},
   year = {2018},
}
@inproceedings{Wagner2010,
   abstract = {Surrogate models, as used for the Design and Analysis of Computer Experiments (DACE), can significantly reduce the resources necessary in cases of expensive evaluations. They provide a prediction of the objective and of the corresponding uncertainty, which can then be combined to a figure of merit for a sequential optimization. In single-objective optimization, the expected improvement (EI) has proven to provide a combination that balances successfully between local and global search. Thus, it has recently been adapted to evolutionary multi-objective optimization (EMO) in different ways. In this paper, we provide an overview of the existing EI extensions for EMO and propose new formulations of the EI based on the hypervolume. We set up a list of necessary and desirable properties, which is used to reveal the strengths and weaknesses of the criteria by both theoretical and experimental analyses. © 2010 Springer-Verlag.},
   author = {Tobias Wagner and Michael Emmerich and André Deutz and Wolfgang Ponweiser},
   doi = {10.1007/978-3-642-15844-5_72},
   isbn = {3642158439},
   issn = {03029743},
   issue = {PART 1},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Design and Analysis of Computer Experiments,Expected Improvement,Hypervolume Indicator,Multi-Objective Optimization},
   pages = {718-727},
   title = {On expected-improvement criteria for model-based multi-objective optimization},
   volume = {6238 LNCS},
   year = {2010},
}
@article{Sanchez2019,
   abstract = {Solubility is a ubiquitous phenomenon in many aspects of science. While solubility can be determined by considering the cohe- sive forces in a liquid via Hansen solubility parameters (HSP), the prediction is often done using Quantitative structure-property relationship models due to its low computational cost. Herein, we report an interpretable and versatile probabilistic approach (gpHSP) to determining HSP. Our model is based on Gaussian processes (GP), a Bayesian machine learning approach, which also provides uncertainty bounds to prediction. gpHSP achieves its flexibility by leveraging a variety of input data, such as SMILES strings, COSMOtherm simulations, and quantum chemistry calculations. gpHSP is built on experimentally determined HSP: a general solvents set aggregated from literature, and a polymer set, in-house characterized. In both sets, we obtained a high degree of agreement, surpassing well-established machine learning methods. We demonstrate the general applicability of gpHSP to miscibility of organic semiconductors, drug compounds and in general solvents, which can be further extended to other domains. gpHSP is a fast and accurate toolbox, which could be applied to molecular design for solution processing technologies.},
   author = {Benjamin Sanchez-Lengeling and Loïc M. Roch and José Darío Perea and Stefan Langner and Christoph J. Brabec and Alán Aspuru-Guzik},
   doi = {10.1002/adts.201800069},
   issue = {1},
   journal = {Advanced Theory and Simulations},
   month = {1},
   pages = {1800069},
   publisher = {Wiley},
   title = {A Bayesian Approach to Predict Solubility Parameters},
   volume = {2},
   year = {2019},
}
@article{Bortz2014,
   abstract = {Designing chemical processes is a multi-criteria optimization problem with conflicting objectives. It can efficiently be solved using Pareto sets. These sets contain all solutions for which an improvement in any objective can only be achieved by accepting a decline in at least one other objective. This work integrates a novel algorithm to determine Pareto sets in a state-of-the-art steady-state flow sheet simulator. An approximation of predefined accuracy of the Pareto set, which can be convex or non-convex, is calculated. The decision maker can then navigate interactively on the Pareto set and explore the different optimal solutions. His decision is, hence, embedded in the knowledge of the entire Pareto set. The application of the method is illustrated by an example in which a distillation process for the separation of an azeotropic mixture (acetone. +. chloroform) is designed. Two process variants are compared: a pressure-swing and an entrainer distillation. © 2013 Elsevier Ltd.},
   author = {M. Bortz and J. Burger and N. Asprion and S. Blagov and R. Böttcher and U. Nowak and A. Scheithauer and R. Welke and K. H. Küfer and H. Hasse},
   doi = {10.1016/j.compchemeng.2013.09.015},
   issn = {00981354},
   journal = {Computers and Chemical Engineering},
   keywords = {Algorithm,Computer-aided process design,Interactive navigation,Multi-objective optimization,Non-convex Pareto frontier,Software tool},
   month = {1},
   pages = {354-363},
   title = {Multi-criteria optimization in chemical process design and decision support by navigation on Pareto sets},
   volume = {60},
   year = {2014},
}
@article{Hernandez2015,
   abstract = {Unknown constraints arise in many types of expensive black-box optimization problems. Several methods have been proposed recently for performing Bayesian optimization with constraints, based on the expected improvement (EI) heuristic. However, EI can lead to pathologies when used with constraints. For example, in the case of decoupled constraints---i.e., when one can independently evaluate the objective or the constraints---EI can encounter a pathology that prevents exploration. Additionally, computing EI requires a current best solution, which may not exist if none of the data collected so far satisfy the constraints. By contrast, information-based approaches do not suffer from these failure modes. In this paper, we present a new information-based method called Predictive Entropy Search with Constraints (PESC). We analyze the performance of PESC and show that it compares favorably to EI-based approaches on synthetic and benchmark problems, as well as several real-world examples. We demonstrate that PESC is an effective algorithm that provides a promising direction towards a unified solution for constrained Bayesian optimization.},
   author = {José Miguel Hernández-Lobato and Michael A. Gelbart and Matthew W. Hoffman and Ryan P. Adams and Zoubin Ghahramani},
   title = {Predictive Entropy Search for Bayesian Optimization with Unknown Constraints},
   year = {2015},
}
@article{Wang2017,
   abstract = {Entropy Search (ES) and Predictive Entropy Search (PES) are popular and empirically successful Bayesian Optimization techniques. Both rely on a compelling information-theoretic motivation, and maximize the information gained about the $\arg\max$ of the unknown function; yet, both are plagued by the expensive computation for estimating entropies. We propose a new criterion, Max-value Entropy Search (MES), that instead uses the information about the maximum function value. We show relations of MES to other Bayesian optimization methods, and establish a regret bound. We observe that MES maintains or improves the good empirical performance of ES/PES, while tremendously lightening the computational burden. In particular, MES is much more robust to the number of samples used for computing the entropy, and hence more efficient for higher dimensional problems.},
   author = {Zi Wang and Stefanie Jegelka},
   title = {Max-value Entropy Search for Efficient Bayesian Optimization},
   year = {2017},
}
@article{Kandasamy2017,
   abstract = {We design and analyse variations of the classical Thompson sampling (TS) procedure for Bayesian optimisation (BO) in settings where function evaluations are expensive, but can be performed in parallel. Our theoretical analysis shows that a direct application of the sequential Thompson sampling algorithm in either synchronous or asynchronous parallel settings yields a surprisingly powerful result: making $n$ evaluations distributed among $M$ workers is essentially equivalent to performing $n$ evaluations in sequence. Further, by modeling the time taken to complete a function evaluation, we show that, under a time constraint, asynchronously parallel TS achieves asymptotically lower regret than both the synchronous and sequential versions. These results are complemented by an experimental analysis, showing that asynchronous TS outperforms a suite of existing parallel BO algorithms in simulations and in a hyper-parameter tuning application in convolutional neural networks. In addition to these, the proposed procedure is conceptually and computationally much simpler than existing work for parallel BO.},
   author = {Kirthevasan Kandasamy and Akshay Krishnamurthy and Jeff Schneider and Barnabas Poczos},
   title = {Asynchronous Parallel Bayesian Optimisation via Thompson Sampling},
   year = {2017},
}
@article{Matthews2016,
   abstract = {GPflow is a Gaussian process library that uses TensorFlow for its core computations and Python for its front end. The distinguishing features of GPflow are that it uses variational inference as the primary approximation method, provides concise code through the use of automatic differentiation, has been engineered with a particular emphasis on software testing and is able to exploit GPU hardware.},
   author = {Alexander G. de G. Matthews and Mark van der Wilk and Tom Nickson and Keisuke Fujii and Alexis Boukouvalas and Pablo León-Villagrá and Zoubin Ghahramani and James Hensman},
   title = {GPflow: A Gaussian process library using TensorFlow},
   year = {2016},
}
@article{Snoek2015,
   abstract = {Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.},
   author = {Jasper Snoek and Oren Rippel and Kevin Swersky and Ryan Kiros and Nadathur Satish and Narayanan Sundaram and Md. Mostofa Ali Patwary and  Prabhat and Ryan P. Adams},
   title = {Scalable Bayesian Optimization Using Deep Neural Networks},
   year = {2015},
}
@article{Feliot2017,
   abstract = {This article addresses the problem of derivative-free (single- or multi-objective) optimization subject to multiple inequality constraints. Both the objective and constraint functions are assumed to be smooth, non-linear and expensive to evaluate. As a consequence, the number of evaluations that can be used to carry out the optimization is very limited, as in complex industrial design optimization problems. The method we propose to overcome this difficulty has its roots in both the Bayesian and the multi-objective optimization literatures. More specifically, an extended domination rule is used to handle objectives and constraints in a unified way, and a corresponding expected hyper-volume improvement sampling criterion is proposed. This new criterion is naturally adapted to the search of a feasible point when none is available, and reduces to existing Bayesian sampling criteria---the classical Expected Improvement (EI) criterion and some of its constrained/multi-objective extensions---as soon as at least one feasible point is available. The calculation and optimization of the criterion are performed using Sequential Monte Carlo techniques. In particular, an algorithm similar to the subset simulation method, which is well known in the field of structural reliability, is used to estimate the criterion. The method, which we call BMOO (for Bayesian Multi-Objective Optimization), is compared to state-of-the-art algorithms for single- and multi-objective constrained optimization.},
   author = {Paul Feliot and Julien Bect and Emmanuel Vazquez},
   doi = {10.1007/s10898-016-0427-3},
   issn = {15732916},
   issue = {1-2},
   journal = {Journal of Global Optimization},
   title = {A Bayesian approach to constrained single- and multi-objective optimization},
   volume = {67},
   year = {2017},
}
@article{Martinez2016,
   abstract = {This paper proposes a novel infill sampling criterion for constraint handling in multi-objective optimization of computationally expensive black-box functions. To reduce the computational burden, Kriging models are used to emulate the objective and constraint functions. The challenge of this multi-objective optimization problem arises from the fact that the epistemic uncertainty of the Kriging models should be taken into account to find Pareto-optimal solutions in the feasible domain. This is done by the proposed sampling criterion combining the Expected HyperVolume Improvement of the front of nondominated solutions and the Probability of Feasibility of new candidates. The proposed criterion is non-intrusive and derivative-free, and it is oriented to: (1) problems in which the computational cost is mainly from the function evaluation rather than optimization, and (2) problems that use complex in-house or commercial software that cannot be modified. The results using the proposed sampling criterion are compared with the results using Multi-Objective Evolutionary Algorithms. These results show that the proposed sampling criterion permits to identify both the feasible domain and an approximation of the Pareto front using a reduced number of computationally expensive simulations.},
   author = {Jesús Martínez-Frutos and David Herrero-Pérez},
   doi = {10.1007/s10898-015-0370-8},
   issn = {15732916},
   issue = {1},
   journal = {Journal of Global Optimization},
   title = {Kriging-based infill sampling criterion for constraint handling in multi-objective optimization},
   volume = {64},
   year = {2016},
}
@inproceedings{Frazier2015,
   abstract = {We introduce Bayesian optimization, a technique developed for optimizing time-consuming engineering simulations and for fitting machine learning models on large datasets. Bayesian optimization guides the choice of experiments during materials design and discovery to find good material designs in as few experiments as possible. We focus on the case when materials designs are parameterized by a low-dimensional vector. Bayesian optimization is built on a statistical technique called Gaussian process regression, which allows predicting the performance of a new design based on previously tested designs. After providing a detailed introduction to Gaussian process regression, we introduce two Bayesian optimization methods: expected improvement, for design problems with noise-free evaluations; and the knowledge-gradient method, which generalizes expected improvement and may be used in design problems with noisy evaluations. Both methods are derived using a value-of-information analysis, and enjoy one-step Bayes-optimality.},
   author = {Peter I. Frazier and Jialei Wang},
   doi = {10.1007/978-3-319-23871-5_3},
   isbn = {9783319238708},
   issn = {0933033X},
   journal = {Springer Series in Materials Science},
   title = {Bayesian optimization for materials design},
   volume = {225},
   year = {2015},
}
@article{Moriconi2019,
   abstract = {Bayesian optimization (BO) is a powerful approach for seeking the global optimum of expensive black-box functions and has proven successful for fine tuning hyper-parameters of machine learning models. The Bayesian optimization routine involves learning a response surface and maximizing a score to select the most valuable inputs to be queried at the next iteration. These key steps are subject to the curse of dimensionality so that Bayesian optimization does not scale beyond 10--20 parameters. In this work, we address this issue and propose a high-dimensional BO method that learns a nonlinear low-dimensional manifold of the input space. We achieve this with a multi-layer neural network embedded in the covariance function of a Gaussian process. This approach applies unsupervised dimensionality reduction as a byproduct of a supervised regression solution. This also allows exploiting data efficiency of Gaussian process models in a Bayesian framework. We also introduce a nonlinear mapping from the manifold to the high-dimensional space based on multi-output Gaussian processes and jointly train it end-to-end via marginal likelihood maximization. We show this intrinsically low-dimensional optimization outperforms recent baselines in high-dimensional BO literature on a set of benchmark functions in 60 dimensions.},
   author = {Riccardo Moriconi and K. S. Sesh Kumar and Marc P. Deisenroth},
   journal = {arXiv preprint},
   title = {High-Dimensional Bayesian Optimization with Manifold Gaussian Processes},
   year = {2019},
}
@article{Huang2017,
   abstract = { A powerful material discovery tool is invented by combining SSW global optimization with neural network computing, which identifies unprecedented TiO 2 phases.  While the underlying potential energy surface (PES) determines the structure and other properties of a material, it has been frustrating to predict new materials from theory even with the advent of supercomputing facilities. The accuracy of the PES and the efficiency of PES sampling are two major bottlenecks, not least because of the great complexity of the material PES. This work introduces a “Global-to-Global” approach for material discovery by combining for the first time a global optimization method with neural network (NN) techniques. The novel global optimization method, named the stochastic surface walking (SSW) method, is carried out massively in parallel for generating a global training data set, the fitting of which by the atom-centered NN produces a multi-dimensional global PES; the subsequent SSW exploration of large systems with the analytical NN PES can provide key information on the thermodynamics and kinetics stability of unknown phases identified from global PESs. We describe in detail the current implementation of the SSW-NN method with particular focuses on the size of the global data set and the simultaneous energy/force/stress NN training procedure. An important functional material, TiO 2 , is utilized as an example to demonstrate the automated global data set generation, the improved NN training procedure and the application in material discovery. Two new TiO 2 porous crystal structures are identified, which have similar thermodynamics stability to the common TiO 2 rutile phase and the kinetics stability for one of them is further proved from SSW pathway sampling. As a general tool for material simulation, the SSW-NN method provides an efficient and predictive platform for large-scale computational material screening. },
   author = {Si Da Huang and Cheng Shang and Xiao Jie Zhang and Zhi Pan Liu},
   doi = {10.1039/c7sc01459g},
   issn = {20416539},
   journal = {Chemical Science},
   title = {Material discovery by combining stochastic surface walking global optimization with a neural network},
   year = {2017},
}
@article{Wilson2013,
   author = {Andrew Gordon Wilson and Elad Gilboa and Arye Nehorai and John P. Cunningham},
   month = {10},
   title = {GPatt: Fast Multidimensional Pattern Extrapolation with Gaussian Processes},
   url = {https://arxiv.org/abs/1310.5288},
   year = {2013},
}
@article{Kandasamy2019,
   author = {Kirthevasan Kandasamy and Karun Raju Vysyaraju and Willie Neiswanger and Biswajit Paria and Christopher R. Collins and Jeff Schneider and Barnabas Poczos and Eric P. Xing},
   month = {3},
   title = {Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly},
   url = {https://arxiv.org/abs/1903.06694},
   year = {2019},
}
@article{Qin2017,
   abstract = {The expected improvement (EI) algorithm is a popular strategy for information collection in optimization under uncertainty. The algorithm is widely known to be too greedy, but nevertheless enjoys wide use due to its simplicity and ability to handle uncertainty and noise in a coherent decision theoretic framework. To provide rigorous insight into EI, we study its properties in a simple setting of Bayesian optimization where the domain consists of a finite grid of points. This is the so-called best-arm identification problem, where the goal is to allocate measurement effort wisely to confidently identify the best arm using a small number of measurements. In this framework, one can show formally that EI is far from optimal. To overcome this shortcoming, we introduce a simple modification of the expected improvement algorithm. Surprisingly, this simple change results in an algorithm that is asymptotically optimal for Gaussian best-arm identification problems, and provably outperforms standard EI by an order of magnitude.},
   author = {Chao Qin and Diego Klabjan and Daniel Russo},
   month = {5},
   title = {Improving the Expected Improvement Algorithm},
   url = {http://arxiv.org/abs/1705.10033},
   year = {2017},
}
@article{Zhao2018,
   abstract = {In multi-objective Bayesian optimization and surrogate-based evolutionary algorithms, Expected HyperVolume Improvement (EHVI) is widely used as the acquisition function to guide the search approaching the Pareto front. This paper focuses on the exact calculation of EHVI given a nondominated set, for which the existing exact algorithms are complex and can be inefficient for problems with more than three objectives. Integrating with different decomposition algorithms, we propose a new method for calculating the integral in each decomposed high-dimensional box in constant time. We develop three new exact EHVI calculation algorithms based on three region decomposition methods. The first grid-based algorithm has a complexity of $O(m\cdot n^m)$ with $n$ denoting the size of the nondominated set and $m$ the number of objectives. The Walking Fish Group (WFG)-based algorithm has a worst-case complexity of $O(m\cdot 2^n)$ but has a better average performance. These two can be applied for problems with any $m$. The third CLM-based algorithm is only for $m=3$ and asymptotically optimal with complexity $\Theta(n\log\{n\})$. Performance comparison results show that all our three algorithms are at least twice faster than the state-of-the-art algorithms with the same decomposition methods. When $m>3$, our WFG-based algorithm can be over $10^2$ faster than the corresponding existing algorithms. Our algorithm is demonstrated in an example involving efficient multi-objective material design with Bayesian optimization.},
   author = {Guang Zhao and Raymundo Arroyave and Xiaoning Qian},
   month = {12},
   title = {Fast Exact Computation of Expected HyperVolume Improvement},
   url = {http://arxiv.org/abs/1812.07692},
   year = {2018},
}
@article{Zhou2017,
   abstract = {Deep reinforcement learning was employed to optimize chemical reactions. Our model iteratively records the results of a chemical reaction and chooses new experimental conditions to improve the reaction outcome. This model outperformed a state-of-the-art blackbox optimization algorithm by using 71% fewer steps on both simulations and real reactions. Furthermore, we introduced an efficient exploration strategy by drawing the reaction conditions from certain probability distributions, which resulted in an improvement on regret from 0.062 to 0.039 compared with a deterministic policy. Combining the efficient exploration policy with accelerated microdroplet reactions, optimal reaction conditions were determined in 30 min for the four reactions considered, and a better understanding of the factors that control microdroplet reactions was reached. Moreover, our model showed a better performance after training on reactions with similar or even dissimilar underlying mechanisms, which demonstrates its learning ability.},
   author = {Zhenpeng Zhou and Xiaocheng Li and Richard N. Zare},
   doi = {10.1021/acscentsci.7b00492},
   issn = {23747951},
   journal = {ACS Central Science},
   title = {Optimizing Chemical Reactions with Deep Reinforcement Learning},
   year = {2017},
}
@article{Picheny2016,
   abstract = {An augmented Lagrangian (AL) can convert a constrained optimization problem into a sequence of simpler (e.g., unconstrained) problems, which are then usually solved with local solvers. Recently, surrogate-based Bayesian optimization (BO) sub-solvers have been successfully deployed in the AL framework for a more global search in the presence of inequality constraints; however, a drawback was that expected improvement (EI) evaluations relied on Monte Carlo. Here we introduce an alternative slack variable AL, and show that in this formulation the EI may be evaluated with library routines. The slack variables furthermore facilitate equality as well as inequality constraints, and mixtures thereof. We show our new slack "ALBO" compares favorably to the original. Its superiority over conventional alternatives is reinforced on several mixed constraint examples.},
   author = {Victor Picheny and Robert B. Gramacy and Stefan Wild and Sébastien Le Digabel},
   issn = {10495258},
   journal = {Advances in Neural Information Processing Systems},
   title = {Bayesian optimization under mixed constraints with a slack-variable augmented Lagrangian},
   year = {2016},
}
@article{Martinez2015,
   abstract = {BayesOpt is a library with state-of-the-art Bayesian optimization methods to solve nonlin-ear optimization, stochastic bandits or sequential experimental design problems. Bayesian optimization characterized for being sample efficient as it builds a posterior distribution to capture the evidence and prior knowledge of the target function. Built in standard C++, the library is extremely efficient while being portable and exible. It includes a common interface for C, C++, Python, Matlab and Octave.},
   author = {Ruben Martinez-Cantin},
   issn = {15337928},
   journal = {Journal of Machine Learning Research},
   title = {BayesOpt: A Bayesian optimization library for nonlinear optimization, experimental design and bandits},
   year = {2015},
}
@article{Wang2017,
   abstract = {Optimization of high-dimensional black-box functions is an extremely challenging problem. While Bayesian optimization has emerged as a popular approach for optimizing black-box functions, its applicability has been limited to low-dimensional problems due to its computational and statistical challenges arising from high-dimensional settings. In this paper, we propose to tackle these challenges by (1) assuming a latent additive structure in the function and inferring it properly for more efficient and effective BO, and (2) performing multiple evaluations in parallel to reduce the number of iterations required by the method. Our novel approach learns the latent structure with Gibbs sampling and constructs batched queries using dctcrminantal point processes. Experimental validations on both synthetic and real-world functions demonstrate that the proposed method outperforms the existing state-of-the-art approaches.},
   author = {Zi Wang and Chengtao Li and Stefanie Jegelka and Pushmeet Kohli},
   isbn = {9781510855144},
   journal = {34th International Conference on Machine Learning, ICML 2017},
   title = {Batched high-dimensional Bayesian optimization via structural kernel learning},
   year = {2017},
}
@article{Poscharny2018,
   abstract = {A methodology for the synthesis of oxetanes from benzophenone and furan derivatives is presented. UV-light irradiation in batch and flow systems allowed the [2 + 2] cycloaddition reaction to proceed and a broad range of oxetanes could be synthesized in manual and automated fashion. The identification of high-yielding reaction parameters was achieved through a new self-optimizing photoreactor system.},
   author = {K. Poscharny and D. C. Fabry and S. Heddrich and E. Sugiono and M. A. Liauw and M. Rueping},
   doi = {10.1016/j.tet.2018.04.019},
   issn = {14645416},
   journal = {Tetrahedron},
   title = {Machine assisted reaction optimization: A self-optimizing reactor system for continuous-flow photochemical reactions},
   year = {2018},
}
@article{Tracey2018,
   abstract = {Gaussian process priors are commonly used in aerospace design for performing Bayesian optimization. Nonetheless, Gaussian processes suffer two significant drawbacks: outliers are a priori assumed unlikely, and the posterior variance conditioned on observed data depends only on the locations of those data, not the associated sample values. Student's-T processes are a generalization of Gaussian processes, founded on the Student's-T distribution instead of the Gaussian distribution. Student's-T processes maintain the primary advantages of Gaussian processes (kernel function, analytic update rule) with additional benefits beyond Gaussian processes. The Student's-T distribution has higher Kurtosis than a Gaussian distribution and so outliers are much more likely, and the posterior variance increases or decreases depending on the variance of observed data sample values. Here, we describe Student's-T processes, and discuss their advantages in the context of aerospace optimization. We show how to construct a Student's-T process using a kernel function and how to update the process given new samples. We provide a clear derivation of optimization-relevant quantities such as expected improvement, and contrast with the related computations for Gaussian processes. Finally, we compare the performance of Student's-T processes against Gaussian process on canonical test problems in Bayesian optimization, and apply the Student's-T process to the optimization of an aerostructural design problem.},
   author = {Brendan D. Tracey and David Wolpert},
   doi = {10.2514/6.2018-1659},
   title = {Upgrading from Gaussian Processes to Student’s-T Processes},
   url = {http://www.mendeley.com/research/upgrading-gaussian-processes-studentst-processes},
   year = {2018},
}
@article{Emmerich2018,
   author = {Michael T. M. Emmerich and André H. Deutz},
   doi = {10.1007/s11047-018-9685-y},
   issue = {3},
   journal = {Nat Comput.},
   pages = {585-609},
   title = {A tutorial on multiobjective optimization: fundamentals and evolutionary methods},
   volume = {17},
   year = {2018},
}
@article{Pascoletti1984,
   abstract = {A scalarization of vector optimization problems is proposed, where optimality is defined through convex cones. By varying the parameters of the scalar problem, it is possible to find all vector optima from the scalar ones. Moreover, it is shown that, under mild assumptions, the dependence is differentiable for smooth objective maps defined over reflexive Banach spaces. A sufficiency condition of optimality for a general mathematical programming problem is also given in the Appendix.},
   author = {P. Pascoletti and A. Serafini},
   doi = {10.1007/BF00934564},
   issn = {1573-2878},
   issue = {4},
   journal = {Journal of Optimization Theory and Applications},
   month = {4},
   pages = {499-524},
   title = {Scalarizing vector optimization problems},
   volume = {42},
   url = {https://doi.org/10.1007/BF00934564},
   year = {1984},
}
@article{Das1998,
   abstract = {This paper proposes an alternate method for finding several Pareto optimal points for a general nonlinear multicriteria optimization problem. Such points collectively capture the trade-off among the various conflicting objectives. It is proved that this method is independent of the relative scales of the functions and is successful in producing an evenly distributed set of points in the Pareto set given an evenly distributed set of parameters, a property which the popular method of minimizing weighted combinations of objective functions lacks. Further, this method can handle more than two objectives while retaining the computational efficiency of continuation-type algorithms. This is an improvement over continuation techniques for tracing the trade-off curve since continuation strategies cannot easily be extended to handle more than two objectives.},
   author = {Indraneel Das and J. E. Dennis},
   doi = {10.1137/S1052623496307510},
   issue = {3},
   journal = {SIAM Journal on Optimization},
   keywords = {Multicriteria optimization,Multiobjective optimization,Pareto set,Trade-off curve},
   pages = {631-657},
   publisher = {Society for Industrial and Applied Mathematics Publications},
   title = {Normal-boundary intersection: A new method for generating the Pareto surface in nonlinear multicriteria optimization problems},
   volume = {8},
   year = {1998},
}
@inproceedings{Coello2015,
   abstract = {Evolutionary Algorithms (EAs), when used for global optimization, can be seen as unconstrained optimization techniques. Therefore, they require an additional mechanism to incorporate constraints of any kind (i.e., inequality, equality, linear, nonlinear) into their fitness function. Although the use of penalty functions (very popular with mathematical programming techniques) may seem an obvious choice, this sort of approach requires a careful fine tuning of the penalty factors to be used. Otherwise, an EA may be unable to reach the feasible region (if the penalty is too low) or may reach quickly the feasible region but being unable to locate solutions that lie in the boundary with the infeasible region (if the penalty is too severe). This has motivated the development of a number of approaches to incorporate constraints into the fitness function of an EA. This tutorial will cover the main proposals in current use, including novel approaches such as the use of tournament rules based on feasibility, multiobjective optimization concepts, hybrids with mathematical programming techniques (e.g., Lagrange multipliers), cultural algorithms, and artificial immune systems, among others. Other topics such as the importance of maintaining diversity, current benchmarks and the use of alternative search engines (e.g., particle swarm optimization, differential evolution, evolution strategies, etc.) will be also discussed (as time allows).},
   author = {Carlos A. Coello Coello},
   doi = {10.1145/2739482.2756561},
   isbn = {9781450334884},
   journal = {GECCO 2015 - Companion Publication of the 2015 Genetic and Evolutionary Computation Conference},
   title = {Constraint-handling techniques used with Evolutionary Algorithms},
   year = {2015},
}
@article{Balandat2019,
   abstract = {Bayesian optimization provides sample-efficient global optimization for a broad range of applications, including automatic machine learning, molecular chemistry, and experimental design. We introduce BoTorch, a modern programming framework for Bayesian optimization. Enabled by Monte-Carlo (MC) acquisition functions and auto-differentiation, BoTorch's modular design facilitates flexible specification and optimization of probabilistic models written in PyTorch, radically simplifying implementation of novel acquisition functions. Our MC approach is made practical by a distinctive algorithmic foundation that leverages fast predictive distributions and hardware acceleration. In experiments, we demonstrate the improved sample efficiency of BoTorch relative to other popular libraries. BoTorch is open source and available at https://github.com/pytorch/botorch.},
   author = {Maximilian Balandat and Brian Karrer and Daniel R. Jiang and Samuel Daulton and Benjamin Letham and Andrew Gordon Wilson and Eytan Bakshy},
   month = {10},
   title = {BoTorch: Programmable Bayesian Optimization in PyTorch},
   url = {http://arxiv.org/abs/1910.06403},
   year = {2019},
}
@article{Paria2018,
   abstract = {Many real world applications can be framed as multi-objective optimization problems, where we wish to simultaneously optimize for multiple criteria. Bayesian optimization techniques for the multi-objective setting are pertinent when the evaluation of the functions in question are expensive. Traditional methods for multi-objective optimization, both Bayesian and otherwise, are aimed at recovering the Pareto front of these objectives. However, in certain cases a practitioner might desire to identify Pareto optimal points only in a subset of the Pareto front due to external considerations. In this work, we propose a strategy based on random scalarizations of the objectives that addresses this problem. Our approach is able to flexibly sample from desired regions of the Pareto front and, computationally, is considerably cheaper than most approaches for MOO. We also study a notion of regret in the multi-objective setting and show that our strategy achieves sublinear regret. We experiment with both synthetic and real-life problems, and demonstrate superior performance of our proposed algorithm in terms of the flexibility and regret.},
   author = {Biswajit Paria and Kirthevasan Kandasamy and Barnabás Póczos},
   month = {5},
   title = {A Flexible Framework for Multi-Objective Bayesian Optimization using Random Scalarizations},
   url = {http://arxiv.org/abs/1805.12168},
   year = {2018},
}
@book_section{Foster2019,
   author = {Adam Foster and Martin Jankowiak and Elias Bingham and Paul Horsfall and Yee Whye Teh and Thomas Rainforth and Noah Goodman},
   editor = {H Wallach and H Larochelle and A Beygelzimer and F d Alché-Buc and E Fox and R Garnett},
   journal = {Advances in Neural Information Processing Systems 32},
   pages = {14036-14047},
   publisher = {Curran Associates, Inc.},
   title = {Variational Bayesian Optimal Experimental Design},
   url = {http://papers.nips.cc/paper/9553-variational-bayesian-optimal-experimental-design.pdf},
   year = {2019},
}
@article{Dächert2020,
   author = {Kerstin Dächert and Katrin Teichert},
   month = {3},
   title = {An improved hyperboxing algorithm for calculating a Pareto front representation},
   url = {https://arxiv.org/abs/2003.14249},
   year = {2020},
}
@article{Gardner2019,
   abstract = {Automated machine learning has gained a lot of attention recently. Building and selecting the right machine learning models is often a multi-objective optimization problem. General purpose machine learning software that simultaneously supports multiple objectives and constraints is scant, though the potential benefits are great. In this work, we present a framework called Autotune that effectively handles multiple objectives and constraints that arise in machine learning problems. Autotune is built on a suite of derivative-free optimization methods, and utilizes multi-level parallelism in a distributed computing environment for automatically training, scoring, and selecting good models. Incorporation of multiple objectives and constraints in the model exploration and selection process provides the flexibility needed to satisfy trade-offs necessary in practical machine learning applications. Experimental results from standard multi-objective optimization benchmark problems show that Autotune is very efficient in capturing Pareto fronts. These benchmark results also show how adding constraints can guide the search to more promising regions of the solution space, ultimately producing more desirable Pareto fronts. Results from two real-world case studies demonstrate the effectiveness of the constrained multi-objective optimization capability offered by Autotune.},
   author = {Steven Gardner and Oleg Golovidov and Joshua Griffin and Patrick Koch and Wayne Thompson and Brett Wujek and Yan Xu},
   month = {8},
   title = {Constrained Multi-Objective Optimization for Automated Machine Learning},
   url = {http://arxiv.org/abs/1908.04909},
   year = {2019},
}
@article{Pettersson2019,
   author = {William Pettersson and Melih Ozlen},
   doi = {10.1063/1.5090006},
   month = {9},
   title = {Multi-Objective Mixed Integer Programming: An Objective Space Algorithm},
   url = {https://arxiv.org/abs/1909.03829},
   year = {2019},
}
@article{De2019,
   abstract = {The performance of acquisition functions for Bayesian optimisation is investigated in terms of the Pareto front between exploration and exploitation. We show that Expected Improvement and the Upper Confidence Bound always select solutions to be expensively evaluated on the Pareto front, but Probability of Improvement is never guaranteed to do so and Weighted Expected Improvement does only for a restricted range of weights. We introduce two novel $\epsilon$-greedy acquisition functions. Extensive empirical evaluation of these together with random search, purely exploratory and purely exploitative search on 10 benchmark problems in 1 to 10 dimensions shows that $\epsilon$-greedy algorithms are generally at least as effective as conventional acquisition functions, particularly with a limited budget. In higher dimensions $\epsilon$-greedy approaches are shown to have improved performance over conventional approaches. These results are borne out on a real world computational fluid dynamics optimisation problem and a robotics active learning problem.},
   author = {George De Ath and Richard M. Everson and Alma A. M. Rahat and Jonathan E. Fieldsend},
   month = {11},
   title = {Greed is Good: Exploration and Exploitation Trade-offs in Bayesian Optimisation},
   url = {http://arxiv.org/abs/1911.12809},
   year = {2019},
}
@article{Gao2020,
   abstract = {Pareto Front (PF) modeling is essential in decision making problems across all domains such as economics, medicine or engineering. In Operation Research literature, this task has been addressed based on multi-objective optimization algorithms. However, without learning models for PF, these methods cannot examine whether a new provided point locates on PF or not. In this paper, we reconsider the task from Data Mining perspective. A novel projection based active Gaussian process regression (P- aGPR) method is proposed for efficient PF modeling. First, P- aGPR chooses a series of projection spaces with dimensionalities ranking from low to high. Next, in each projection space, a Gaussian process regression (GPR) model is trained to represent the constraint that PF should satisfy in that space. Moreover, in order to improve modeling efficacy and stability, an active learning framework has been developed by exploiting the uncertainty information obtained in the GPR models. Different from all existing methods, our proposed P-aGPR method can not only provide a generative PF model, but also fast examine whether a provided point locates on PF or not. The numerical results demonstrate that compared to state-of-the-art passive learning methods the proposed P-aGPR method can achieve higher modeling accuracy and stability.},
   author = {Zhengqi Gao and Jun Tao and Yangfeng Su and Dian Zhou and Xuan Zeng},
   month = {1},
   title = {Projection based Active Gaussian Process Regression for Pareto Front Modeling},
   url = {http://arxiv.org/abs/2001.07072},
   year = {2020},
}
@article{Iqbal2020,
   abstract = {One of the key challenges in designing machine learning systems is to determine the right balance amongst several objectives, which also oftentimes are incommensurable and conflicting. For example, when designing deep neural networks (DNNs), one often has to trade-off between multiple objectives, such as accuracy, energy consumption, and inference time. Typically, there is no single configuration that performs equally well for all objectives. Consequently, one is interested in identifying Pareto-optimal designs. Although different multi-objective optimization algorithms have been developed to identify Pareto-optimal configurations, state-of-the-art multi-objective optimization methods do not consider the different evaluation costs attending the objectives under consideration. This is particularly important for optimizing DNNs: the cost arising on account of assessing the accuracy of DNNs is orders of magnitude higher than that of measuring the energy consumption of pre-trained DNNs. We propose FlexiBO, a flexible Bayesian optimization method, to address this issue. We formulate a new acquisition function based on the improvement of the Pareto hyper-volume weighted by the measurement cost of each objective. Our acquisition function selects the next sample and objective that provides maximum information gain per unit of cost. We evaluated FlexiBO on 7 state-of-the-art DNNs for object detection, natural language processing, and speech recognition. Our results indicate that, when compared to other state-of-the-art methods across the 7 architectures we tested, the Pareto front obtained using FlexiBO has, on average, a 28.44% higher contribution to the true Pareto front and achieves 25.64% better diversity.},
   author = {Md Shahriar Iqbal and Jianhai Su and Lars Kotthoff and Pooyan Jamshidi},
   month = {1},
   title = {FlexiBO: Cost-Aware Multi-Objective Optimization of Deep Neural Networks},
   url = {http://arxiv.org/abs/2001.06588},
   year = {2020},
}
@article{Meneghini2020,
   abstract = {Solving many-objective problems (MaOPs) is still a significant challenge in the multi-objective optimization (MOO) field. One way to measure algorithm performance is through the use of benchmark functions (also called test functions or test suites), which are artificial problems with a well-defined mathematical formulation, known solutions and a variety of features and difficulties. In this paper we propose a parameterized generator of scalable and customizable benchmark problems for MaOPs. It is able to generate problems that reproduce features present in other benchmarks and also problems with some new features. We propose here the concept of generative benchmarking, in which one can generate an infinite number of MOO problems, by varying parameters that control specific features that the problem should have: scalability in the number of variables and objectives, bias, deceptiveness, multimodality, robust and non-robust solutions, shape of the Pareto front, and constraints. The proposed Generalized Position-Distance (GPD) tunable benchmark generator uses the position-distance paradigm, a basic approach to building test functions, used in other benchmarks such as Deb, Thiele, Laumanns and Zitzler (DTLZ), Walking Fish Group (WFG) and others. It includes scalable problems in any number of variables and objectives and it presents Pareto fronts with different characteristics. The resulting functions are easy to understand and visualize, easy to implement, fast to compute and their Pareto optimal solutions are known.},
   author = {Ivan Reinaldo Meneghini and Marcos Antonio Alves and António Gaspar-Cunha and Frederico Gadelha Guimarães},
   doi = {10.1016/j.asoc.2020.106139},
   month = {1},
   title = {Scalable and Customizable Benchmark Problems for Many-Objective Optimization},
   url = {http://arxiv.org/abs/2001.11591 http://dx.doi.org/10.1016/j.asoc.2020.106139},
   year = {2020},
}
@article{Nowak2020,
   abstract = {A new interactive approach to navigate on approximations of in general non-convex but connected Pareto fronts is introduced. Given a finite number of precalculated representative Pareto-efficient solutions, an adapted Delaunay triangulation is generated. Based on interpolation and ray tracing techniques, real time navigation in the vicinity of Pareto-optimal solutions is made possible.},
   author = {Dimitri Nowak and Karl-Heinz Küfer},
   month = {1},
   title = {A Ray Tracing Technique for the Navigation on a Non-convex Pareto Front},
   url = {http://arxiv.org/abs/2001.03634},
   year = {2020},
}
@article{Ghane2014,
   abstract = {One of the most important issues in multi-objective optimization problems (MOPs) is finding Pareto optimal points on the Pareto frontier. This topic is one of the oldest challenges in science and engineering. Many important problems in engineering need to solve a non-convex multi-objective optimization problem (NMOP) in order to achieve the proper results. Gradient based methods, such as Normal Boundary Intersection (NBI), for solving a MOP require solving at least one optimization problem for each solution point. This method can be computationally expensive with an increase in the number of variables and/or constraints of the optimization problem. Nevertheless, the NBI method is a technique motivated by geometrical intuition to provide a better parameterization of the Pareto set than that provided by other techniques. This parameterization is better in the sense that the points obtained by using the NBI method produce a more even coverage of the Pareto curve and this coverage does not miss the interesting middle part of the Pareto curve.This useful property, provides an incentive to create a new method. The first step in this study is using a modified convex hull of individual minimum (mCHIM) in each iteration. The second step is introducing an efficient scalarization problem in order to find the Pareto points on the Pareto front. It can be shown that the corresponding solutions of the MOP have uniform spread and also weak Pareto optimal points. It is notable that the NBI and proposed methods are independent of the relative scale of different objective functions. However, it is quite possible that obtaining a solution of the NBI method not be Pareto optimal (not even locally). Actually, this method aims at getting boundary points rather than Pareto optimal points that will lead to these points which may or may not be a Pareto optimal point. The effectiveness of this method is demonstrated with various test problems in convex and non-convex MOP cases. After that, a few test instances of the CEC 2009 (Zhang et al. 2008) using the proposed method are studied. Also, the relationship between the optimal solutions of the scalarized problem and the Pareto solutions of the multi-objective optimization problem is presented by several theorems.},
   author = {A. Ghane-Kanafi and E. Khorram},
   doi = {10.1016/j.apm.2015.03.022},
   journal = {Applied Mathematical Modelling},
   title = {A new scalarization method for finding the efficient frontier in non-convex multi-objective problems},
   url = {https://www.mendeley.com/catalogue/aba52c00-15fc-3c65-b65e-4b2049056d25/},
   year = {2014},
}
@article{Horn2017,
   abstract = {The performance of many machine learning algorithms heavily depends on the setting of their respective hyperparameters. Many different tuning approaches exist, from simple grid or random search approaches to evolutionary algorithms and Bayesian optimization. Often, these algorithms are used to optimize a single performance criterion. But in practical applications, a single criterion may not be sufficient to adequately characterize the behavior of the machine learning method under consideration and the Pareto front of multiple criteria has to be considered. We propose to use model-based multi-objective optimization to efficiently approximate such Pareto fronts.},
   author = {Daniel Horn and Bernd Bischl},
   doi = {10.1109/SSCI.2016.7850221},
   journal = {2016 IEEE Symposium Series on Computational Intelligence, SSCI 2016},
   title = {Multi-objective parameter configuration of machine learning algorithms using model-based optimization},
   url = {http://www.mendeley.com/research/multiobjective-parameter-configuration-machine-learning-algorithms-using-modelbased-optimization},
   year = {2017},
}
@article{Vien2018,
   abstract = {Bayesian optimization (BayesOpt) is a derivative-free approach for sequentially optimizing stochastic black-box functions. Standard BayesOpt, which has shown many successes in machine learning applications, assumes a finite dimensional domain which often is a parametric space. The parameter space is defined by the features used in the function approximations which are often selected manually. Therefore, the performance of BayesOpt inevitably depends on the quality of chosen features. This paper proposes a new Bayesian optimization framework that is able to optimize directly on the domain of function spaces. The resulting framework, Bayesian Functional Optimization (BFO), not only extends the application domains of BayesOpt to functional optimization problems but also relaxes the performance dependency on the chosen parameter space. We model the domain of functions as a reproducing kernel Hilbert space (RKHS), and use the notion of Gaussian processes on a real separable Hilbert space. As a result, we are able to define traditional improvement-based (PI and EI) and optimistic acquisition functions (UCB) as functionals. We propose to optimize the acquisition functionals using analytic functional gradients that are also proved to be functions in a RKHS. We evaluate BFO in three typical functional optimization tasks: i) a synthetic functional optimization problem, ii) optimizing activation functions for a multi-layer perceptron neural network, and iii) a reinforcement learning task whose policies are modeled in RKHS.},
   author = {Ngo Anh Vien and Heiko Zimmermann and Marc Toussaint},
   journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
   title = {Bayesian functional optimization},
   url = {http://www.mendeley.com/research/bayesian-functional-optimization},
   year = {2018},
}
@article{Kao2008,
   abstract = {Multi-objective optimization algorithms can generate large sets of Pareto optimal (non-dominated) solutions. Identifying the best solutions across a very large number of Pareto optimal solutions can be a challenge. Therefore it is useful for the decision-maker to be able to obtain a small set of preferred Pareto optimal solutions. This paper analyzes a discrete optimization problem introduced to obtain optimal subsets of solutions from large sets of Pareto optimal solutions. This discrete optimization problem is proven to be NP-hard. Two exact algorithms and five heuristics are presented to address this problem. Five test problems are used to compare the performances of these algorithms and heuristics. The results suggest that preferred subset of Pareto optimal solutions can be efficiently obtained using the heuristics, while for smaller problems, exact algorithms can be applied. © 2007 Springer Science+Business Media, LLC.},
   author = {Gio K. Kao and Sheldon H. Jacobson},
   doi = {10.1007/s10589-007-9070-8},
   journal = {Computational Optimization and Applications},
   title = {Finding preferred subsets of Pareto optimal solutions},
   url = {http://www.mendeley.com/research/finding-preferred-subsets-pareto-optimal-solutions},
   year = {2008},
}
@article{Ling2017,
   abstract = {The optimization of composition and processing to obtain materials that exhibit desirable characteristics has historically relied on a combination of scientist intuition, trial and error, and luck. We propose a methodology that can accelerate this process by fitting data-driven models to experimental data as it is collected to suggest which experiment should be performed next. This methodology can guide the scientist to test the most promising candidates earlier, and can supplement scientific intuition and knowledge with data-driven insights. A key strength of the proposed framework is that it scales to high-dimensional parameter spaces, as are typical in materials discovery applications. Importantly, the data-driven models incorporate uncertainty analysis, so that new experiments are proposed based on a combination of exploring high-uncertainty candidates and exploiting high-performing regions of parameter space. Over four materials science test cases, our methodology led to the optimal candidate being found with three times fewer required measurements than random guessing on average.},
   author = {Julia Ling and Max Hutchinson and Erin Antono and Sean Paradiso and Bryce Meredig},
   doi = {10.1007/s40192-017-0098-z},
   month = {4},
   title = {High-Dimensional Materials and Process Optimization using Data-driven Experimental Design with Well-Calibrated Uncertainty Estimates},
   url = {http://arxiv.org/abs/1704.07423 http://dx.doi.org/10.1007/s40192-017-0098-z},
   year = {2017},
}
@article{Schweidtmann2020,
   abstract = {Gaussian processes~(Kriging) are interpolating data-driven models that are frequently applied in various disciplines. Often, Gaussian processes are trained on datasets and are subsequently embedded as surrogate models in optimization problems. These optimization problems are nonconvex and global optimization is desired. However, previous literature observed computational burdens limiting deterministic global optimization to Gaussian processes trained on few data points. We propose a reduced-space formulation for deterministic global optimization with trained Gaussian processes embedded. For optimization, the branch-and-bound solver branches only on the degrees of freedom and McCormick relaxations are propagated through explicit Gaussian process models. The approach also leads to significantly smaller and computationally cheaper subproblems for lower and upper bounding. To further accelerate convergence, we derive envelopes of common covariance functions for GPs and tight relaxations of acquisition functions used in Bayesian optimization including expected improvement, probability of improvement, and lower confidence bound. In total, we reduce computational time by orders of magnitude compared to state-of-the-art methods, thus overcoming previous computational burdens. We demonstrate the performance and scaling of the proposed method and apply it to Bayesian optimization with global optimization of the acquisition function and chance-constrained programming. The Gaussian process models, acquisition functions, and training scripts are available open-source within the "MeLOn - Machine Learning Models for Optimization" toolbox~(https://git.rwth-aachen.de/avt.svt/public/MeLOn).},
   author = {Artur M. Schweidtmann and Dominik Bongartz and Daniel Grothe and Tim Kerkenhoff and Xiaopeng Lin and Jaromil Najman and Alexander Mitsos},
   month = {5},
   title = {Global Optimization of Gaussian processes},
   url = {http://arxiv.org/abs/2005.10902},
   year = {2020},
}
@article{Bisbo2020,
   abstract = {We propose a scheme for global optimization with first-principles energy expressions of atomistic structure. While unfolding its search, the method actively learns a surrogate model of the potential energy landscape on which it performs a number of local relaxations (exploitation) and further structural searches (exploration). Assuming Gaussian processes, deploying two separate kernel widths to better capture rough features of the energy landscape while retaining a good resolution of local minima, an acquisition function is used to decide on which of the resulting structures is the more promising and should be treated at the first-principles level. The method is demonstrated to outperform by 2 orders of magnitude a well established first-principles based evolutionary algorithm in finding surface reconstructions. Finally, global optimization with first-principles energy expressions is utilized to identify initial stages of the edge oxidation and oxygen intercalation of graphene sheets on the Ir(111) surface.},
   author = {Malthe K. Bisbo and Bjørk Hammer},
   doi = {10.1103/PhysRevLett.124.086102},
   issn = {10797114},
   journal = {Physical Review Letters},
   title = {Efficient Global Structure Optimization with a Machine-Learned Surrogate Model},
   year = {2020},
}
@generic{Clayton2019,
   abstract = {Self-optimising chemical systems have experienced a growing momentum in recent years, with the evolution of self-optimising platforms leading to their application for reaction screening and chemical synthesis. With the desire for improved process sustainability, self-optimisation provides a cheaper, faster and greener approach to the chemical development process. The use of such platforms aims to enhance the capabilities of the researcher by removing the need for labor-intensive experimentation, allowing them to focus on more challenging tasks. The establishment of these systems have enabled opportunities for self-optimising platforms to become a key element of a laboratory's repertoire. To enable the wider adoption of self-optimising chemical platforms, this review summarises the history of algorithmic usage in chemical reaction self-optimisation, detailing the functionality of the algorithms and their applications in a way that is accessible for chemists and highlights opportunities for the further exploitation of algorithms in chemical synthesis moving forward.},
   author = {Adam D. Clayton and Jamie A. Manson and Connor J. Taylor and Thomas W. Chamberlain and Brian A. Taylor and Graeme Clemens and Richard A. Bourne},
   doi = {10.1039/c9re00209j},
   issn = {20589883},
   issue = {9},
   journal = {Reaction Chemistry and Engineering},
   month = {9},
   pages = {1545-1554},
   publisher = {Royal Society of Chemistry},
   title = {Algorithms for the self-optimisation of chemical reactions},
   volume = {4},
   year = {2019},
}
@article{Clayton2020,
   abstract = {There has been an increasing interest in the use of automated self-optimising continuous flow platforms for the development and manufacture in synthesis in recent years. Such processes include multiple reactive and work-up steps, which need to be efficiently optimised. Here, we report the combination of multi-objective optimisation based on machine learning methods (TSEMO algorithm) with self-optimising platforms for the optimisation of multi-step continuous reaction processes. This is demonstrated for a pharmaceutically relevant Sonogashira reaction. We demonstrate how optimum reaction conditions are re-evaluated with the changing downstream work-up specifications in the active learning process. Furthermore, a Claisen-Schmidt condensation reaction with subsequent liquid-liquid separation was optimised with respect to three-objectives. This approach provides the ability to simultaneously optimise multi-step processes with respect to multiple objectives, and thus has the potential to make substantial savings in time and resources.},
   author = {Adam D. Clayton and Artur M. Schweidtmann and Graeme Clemens and Jamie A. Manson and Connor J. Taylor and Carlos G. Niño and Thomas W. Chamberlain and Nikil Kapur and A. John Blacker and Alexei A. Lapkin and Richard A. Bourne},
   doi = {10.1016/j.cej.2019.123340},
   issn = {13858947},
   journal = {Chemical Engineering Journal},
   keywords = {Automated flow reactor,Environmental chemistry,Machine learning,Reaction engineering,Sustainable chemistry},
   month = {3},
   publisher = {Elsevier B.V.},
   title = {Automated self-optimisation of multi-step reaction and separation processes using machine learning},
   volume = {384},
   year = {2020},
}
@article{Moss2020,
   author = {Henry B. Moss and David S. Leslie and Paul Rayson},
   month = {6},
   title = {MUMBO: MUlti-task Max-value Bayesian Optimization},
   url = {https://arxiv.org/abs/2006.12093},
   year = {2020},
}
@article{Ma2020,
   abstract = {Bayesian optimization (BO) is a sample-efficient global optimization algorithm for black-box functions which are expensive to evaluate. Existing literature on model based optimization in conditional parameter spaces are usually built on trees. In this work, we generalize the additive assumption to tree-structured functions and propose an additive tree-structured covariance function, showing improved sample-efficiency, wider applicability and greater flexibility. Furthermore, by incorporating the structure information of parameter spaces and the additive assumption in the BO loop, we develop a parallel algorithm to optimize the acquisition function and this optimization can be performed in a low dimensional space. We demonstrate our method on an optimization benchmark function, as well as on a neural network model compression problem, and experimental results show our approach significantly outperforms the current state of the art for conditional parameter optimization including SMAC, TPE and Jenatton et al. (2017).},
   author = {Xingchen Ma and Matthew B. Blaschko},
   month = {6},
   title = {Additive Tree-Structured Covariance Function for Conditional Parameter Spaces in Bayesian Optimization},
   url = {http://arxiv.org/abs/2006.11771},
   year = {2020},
}
@article{Pleiss2020,
   author = {Geoff Pleiss and Martin Jankowiak and David Eriksson and Anil Damle and Jacob R. Gardner},
   month = {6},
   title = {Fast Matrix Square Roots with Applications to Gaussian Processes and Bayesian Optimization},
   url = {https://arxiv.org/abs/2006.11267},
   year = {2020},
}
@article{Luong2020,
   abstract = {Bayesian optimization (BO) is an efficient method for optimizing expensive black-box functions. In real-world applications, BO often faces a major problem of missing values in inputs. The missing inputs can happen in two cases. First, the historical data for training BO often contain missing values. Second, when performing the function evaluation (e.g. computing alloy strength in a heat treatment process), errors may occur (e.g. a thermostat stops working) leading to an erroneous situation where the function is computed at a random unknown value instead of the suggested value. To deal with this problem, a common approach just simply skips data points where missing values happen. Clearly, this naive method cannot utilize data efficiently and often leads to poor performance. In this paper, we propose a novel BO method to handle missing inputs. We first find a probability distribution of each missing value so that we can impute the missing value by drawing a sample from its distribution. We then develop a new acquisition function based on the well-known Upper Confidence Bound (UCB) acquisition function, which considers the uncertainty of imputed values when suggesting the next point for function evaluation. We conduct comprehensive experiments on both synthetic and real-world applications to show the usefulness of our method.},
   author = {Phuc Luong and Dang Nguyen and Sunil Gupta and Santu Rana and Svetha Venkatesh},
   month = {6},
   title = {Bayesian Optimization with Missing Inputs},
   url = {http://arxiv.org/abs/2006.10948},
   year = {2020},
}
@article{Cohen2020,
   abstract = {If we could define the set of all bad outcomes, we could hard-code an agent which avoids them; however, in sufficiently complex environments, this is infeasible. We do not know of any general-purpose approaches in the literature to avoiding novel failure modes. Motivated by this, we define an idealized Bayesian reinforcement learner which follows a policy that maximizes the worst-case expected reward over a set of world-models. We call this agent pessimistic, since it optimizes assuming the worst case. A scalar parameter tunes the agent's pessimism by changing the size of the set of world-models taken into account. Our first main contribution is: given an assumption about the agent's model class, a sufficiently pessimistic agent does not cause "unprecedented events" with probability $1-\delta$, whether or not designers know how to precisely specify those precedents they are concerned with. Since pessimism discourages exploration, at each timestep, the agent may defer to a mentor, who may be a human or some known-safe policy we would like to improve. Our other main contribution is that the agent's policy's value approaches at least that of the mentor, while the probability of deferring to the mentor goes to 0. In high-stakes environments, we might like advanced artificial agents to pursue goals cautiously, which is a non-trivial problem even if the agent were allowed arbitrary computing power; we present a formal solution.},
   author = {Michael K. Cohen and Marcus Hutter},
   month = {6},
   title = {Pessimism About Unknown Unknowns Inspires Conservatism},
   url = {http://arxiv.org/abs/2006.08753},
   year = {2020},
}
@article{Neiswanger2020,
   author = {Willie Neiswanger and Aaditya Ramdas},
   month = {6},
   title = {Uncertainty quantification using martingales for misspecified Gaussian processes},
   url = {https://arxiv.org/abs/2006.07368},
   year = {2020},
}
@article{Kusne2020,
   abstract = {Active learning - the field of machine learning (ML) dedicated to optimal experiment design, has played a part in science as far back as the 18th century when Laplace used it to guide his discovery of celestial mechanics [1]. In this work we focus a closed-loop, active learning-driven autonomous system on another major challenge, the discovery of advanced materials against the exceedingly complex synthesis-processes-structure-property landscape. We demonstrate autonomous research methodology (i.e. autonomous hypothesis definition and evaluation) that can place complex, advanced materials in reach, allowing scientists to fail smarter, learn faster, and spend less resources in their studies, while simultaneously improving trust in scientific results and machine learning tools. Additionally, this robot science enables science-over-the-network, reducing the economic impact of scientists being physically separated from their labs. We used the real-time closed-loop, autonomous system for materials exploration and optimization (CAMEO) at the synchrotron beamline to accelerate the fundamentally interconnected tasks of rapid phase mapping and property optimization, with each cycle taking seconds to minutes, resulting in the discovery of a novel epitaxial nanocomposite phase-change memory material.},
   author = {A. Gilad Kusne and Heshan Yu and Changming Wu and Huairuo Zhang and Jason Hattrick-Simpers and Brian DeCost and Suchismita Sarker and Corey Oses and Cormac Toher and Stefano Curtarolo and Albert V. Davydov and Ritesh Agarwal and Leonid A. Bendersky and Mo Li and Apurva Mehta and Ichiro Takeuchi},
   month = {6},
   title = {On-the-fly Closed-loop Autonomous Materials Discovery via Bayesian Active Learning},
   url = {http://arxiv.org/abs/2006.06141},
   year = {2020},
}
@article{Jung2020,
   abstract = {A spectral mixture (SM) kernel is a flexible kernel used to model any stationary covariance function. Although it is useful in modeling data, the learning of the SM kernel is generally difficult because optimizing a large number of parameters for the SM kernel typically induces an over-fitting, particularly when a gradient-based optimization is used. Also, a longer training time is required. To improve the training, we propose an approximate Bayesian inference for the SM kernel. Specifically, we employ the variational distribution of the spectral points to approximate SM kernel with a random Fourier feature. We optimize the variational parameters by applying a sampling-based variational inference to the derived evidence lower bound (ELBO) estimator constructed from the approximate kernel. To improve the inference, we further propose two additional strategies: (1) a sampling strategy of spectral points to estimate the ELBO estimator reliably and thus its associated gradient, and (2) an approximate natural gradient to accelerate the convergence of the parameters. The proposed inference combined with two strategies accelerates the convergence of the parameters and leads to better optimal parameters.},
   author = {Yohan Jung and Kyungwoo Song and Jinkyoo Park},
   month = {6},
   title = {Approximate Inference for Spectral Mixture Kernel},
   url = {http://arxiv.org/abs/2006.07036},
   year = {2020},
}
@article{Souza2020,
   abstract = {While Bayesian Optimization (BO) is a very popular method for optimizing expensive black-box functions, it fails to leverage the experience of domain experts. This causes BO to waste function evaluations on commonly known bad regions of design choices, e.g., hyperparameters of a machine learning algorithm. To address this issue, we introduce Prior-guided Bayesian Optimization (PrBO). PrBO allows users to inject their knowledge into the optimization process in the form of priors about which parts of the input space will yield the best performance, rather than BO's standard priors over functions which are much less intuitive for users. PrBO then combines these priors with BO's standard probabilistic model to yield a posterior. We show that PrBO is more sample efficient than state-of-the-art methods without user priors and 10,000$\times$ faster than random search, on a common suite of benchmarks and a real-world hardware design application. We also show that PrBO converges faster even if the user priors are not entirely accurate and that it robustly recovers from misleading priors.},
   author = {Artur Souza and Luigi Nardi and Leonardo B. Oliveira and Kunle Olukotun and Marius Lindauer and Frank Hutter},
   month = {6},
   title = {Prior-guided Bayesian Optimization},
   url = {http://arxiv.org/abs/2006.14608},
   year = {2020},
}
@article{Wilson2017,
   abstract = {Bayesian optimization is a sample-efficient approach to solving global optimization problems. Along with a surrogate model, this approach relies on theoretically motivated value heuristics (acquisition functions) to guide the search process. Maximizing acquisition functions yields the best performance; unfortunately, this ideal is difficult to achieve since optimizing acquisition functions per se is frequently non-trivial. This statement is especially true in the parallel setting, where acquisition functions are routinely non-convex, high-dimensional, and intractable. Here, we demonstrate how many popular acquisition functions can be formulated as Gaussian integrals amenable to the reparameterization trick and, ensuingly, gradient-based optimization. Further, we use this reparameterized representation to derive an efficient Monte Carlo estimator for the upper confidence bound acquisition function in the context of parallel selection.},
   author = {James T. Wilson and Riccardo Moriconi and Frank Hutter and Marc Peter Deisenroth},
   month = {12},
   title = {The reparameterization trick for acquisition functions},
   url = {http://arxiv.org/abs/1712.00424},
   year = {2017},
}
@article{Paria2018,
   author = {Biswajit Paria and Kirthevasan Kandasamy and Barnabás Póczos},
   journal = {ArXiv},
   title = {A Flexible Multi-Objective Bayesian Optimization Approach using Random Scalarizations},
   year = {2018},
}
@article{Chang2020,
   abstract = {A major technological challenge in materials research is the large and complex parameter space, which hinders experimental throughput and ultimately slows down development and implementation. In single-walled carbon nanotube (CNT) synthesis, for instance, the poor yield obtained from conventional catalysts is a result of limited understanding of input-to-output correlations. Autonomous closed-loop experimentation combined with advances in machine learning (ML) is uniquely suited for high-throughput research. Among the ML algorithms available, Bayesian optimization (BO) is especially apt for exploration and optimization within such high-dimensional and complex parameter space. BO is an adaptive sequential design algorithm for finding the global optimum of a black-box objective function with the fewest possible measurements. Here, we demonstrate a promising application of BO in CNT synthesis as an efficient and robust algorithm which can (1) improve the growth rate of CNT in the BO-planner experiments over the seed experiments up to a factor 8; (2) rapidly improve its predictive power (or learning); (3) Consistently achieve good performance regardless of the number or origin of seed experiments; (4) exploit a high-dimensional, complex parameter space, and (5) achieve the former 4 tasks in just over 100 hundred experiments (~8 experimental hours) – a factor of 5× faster than our previously reported results.},
   author = {Jorge Chang and Pavel Nikolaev and Jennifer Carpena-Núñez and Rahul Rao and Kevin Decker and Ahmad E. Islam and Jiseob Kim and Mark A. Pitt and Jay I. Myung and Benji Maruyama},
   doi = {10.1038/s41598-020-64397-3},
   issn = {20452322},
   issue = {1},
   journal = {Scientific Reports},
   month = {12},
   pmid = {32493911},
   publisher = {Nature Research},
   title = {Efficient Closed-loop Maximization of Carbon Nanotube Growth Rate using Bayesian Optimization},
   volume = {10},
   year = {2020},
}
@article{Srinivas2009,
   abstract = {Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.},
   author = {Niranjan Srinivas and Andreas Krause and Sham M. Kakade and Matthias Seeger},
   doi = {10.1109/TIT.2011.2182033},
   month = {12},
   title = {Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design},
   url = {http://arxiv.org/abs/0912.3995 http://dx.doi.org/10.1109/TIT.2011.2182033},
   year = {2009},
}
@article{Qin2017,
   abstract = {The expected improvement (EI) algorithm is a popular strategy for information collection in optimization under uncertainty. The algorithm is widely known to be too greedy, but nevertheless enjoys wide use due to its simplicity and ability to handle uncertainty and noise in a coherent decision theoretic framework. To provide rigorous insight into EI, we study its properties in a simple setting of Bayesian optimization where the domain consists of a finite grid of points. This is the so-called best-arm identification problem, where the goal is to allocate measurement effort wisely to confidently identify the best arm using a small number of measurements. In this framework, one can show formally that EI is far from optimal. To overcome this shortcoming, we introduce a simple modification of the expected improvement algorithm. Surprisingly, this simple change results in an algorithm that is asymptotically optimal for Gaussian best-arm identification problems, and provably outperforms standard EI by an order of magnitude.},
   author = {Chao Qin and Diego Klabjan and Daniel Russo},
   month = {5},
   title = {Improving the Expected Improvement Algorithm},
   url = {http://arxiv.org/abs/1705.10033},
   year = {2017},
}
@article{Wang2015,
   abstract = {Recently, there has been rising interest in Bayesian optimization -- the optimization of an unknown function with assumptions usually expressed by a Gaussian Process (GP) prior. We study an optimization strategy that directly uses an estimate of the argmax of the function. This strategy offers both practical and theoretical advantages: no tradeoff parameter needs to be selected, and, moreover, we establish close connections to the popular GP-UCB and GP-PI strategies. Our approach can be understood as automatically and adaptively trading off exploration and exploitation in GP-UCB and GP-PI. We illustrate the effects of this adaptive tuning via bounds on the regret as well as an extensive empirical evaluation on robotics and vision tasks, demonstrating the robustness of this strategy for a range of performance criteria.},
   author = {Zi Wang and Bolei Zhou and Stefanie Jegelka},
   month = {10},
   title = {Optimization as Estimation with Gaussian Processes in Bandit Settings},
   url = {http://arxiv.org/abs/1510.06423},
   year = {2015},
}
@article{Scott2011,
   author = {Warren Scott and Peter Frazier and Warren Powell},
   doi = {10.1137/100801275},
   issue = {3},
   journal = {SIAM Journal on Optimization},
   pages = {996-1026},
   title = {The Correlated Knowledge Gradient for Simulation Optimization of Continuous Parameters using Gaussian Process Regression},
   volume = {21},
   url = {https://doi.org/10.1137/100801275},
   year = {2011},
}
@article{Frazier2009,
   abstract = { We consider a Bayesian ranking and selection problem with independent normal rewards and a correlated multivariate normal belief on the mean values of these rewards. Because this formulation of the ranking and selection problem models dependence between alternatives' mean values, algorithms may use this dependence to perform efficiently even when the number of alternatives is very large. We propose a fully sequential sampling policy called the knowledge-gradient policy, which is provably optimal in some special cases and has bounded suboptimality in all others. We then demonstrate how this policy may be applied to efficiently maximize a continuous function on a continuous domain while constrained to a fixed number of noisy measurements. },
   author = {Peter Frazier and Warren Powell and Savas Dayanik},
   doi = {10.1287/ijoc.1080.0314},
   issue = {4},
   journal = {INFORMS Journal on Computing},
   pages = {599-613},
   title = {The Knowledge-Gradient Policy for Correlated Normal Beliefs},
   volume = {21},
   url = {https://doi.org/10.1287/ijoc.1080.0314},
   year = {2009},
}
@article{Kushner1964,
   author = {H. J. Kushner},
   doi = {10.1115/1.3653121},
   journal = {J. Basic Eng.},
   pages = {97-106},
   title = {A New Method of Locating the Maximum Point of an Arbitrary Multipeak Curve in the Presence of Noise},
   volume = {86},
   url = {https://doi.org/10.1115/1.3653121},
   year = {1964},
}
@article{Mockus1974,
   author = {J. Mockus},
   title = {On Bayesian Methods for Seeking the Extremum},
   url = {https://link.springer.com/content/pdf/10.1007/3-540-07165-2_55.pdf},
   year = {1974},
}
@article{Auer2003,
   author = {Peter Auer},
   issn = {1532-4435},
   issue = {null},
   journal = {J. Mach. Learn. Res.},
   keywords = {bandit problem,exploitation-exploration,linear value function,online Learning,reinforcement learning},
   month = {3},
   pages = {397-422},
   publisher = {JMLR.org},
   title = {Using Confidence Bounds for Exploitation-Exploration Trade-Offs},
   volume = {3},
   year = {2003},
}
@article{Rosario2019,
   abstract = {Discovering novel materials can be greatly accelerated by iterative machine learning-informed proposal of candidates---active learning. However, standard \emph\{global-scope error\} metrics for model quality are not predictive of discovery performance, and can be misleading. We introduce the notion of \emph\{Pareto shell-scope error\} to help judge the suitability of a model for proposing material candidates. Further, through synthetic cases and a thermoelectric dataset, we probe the relation between acquisition function fidelity and active learning performance. Results suggest novel diagnostic tools, as well as new insights for acquisition function design.},
   author = {Zachary del Rosario and Matthias Rupp and Yoolhee Kim and Erin Antono and Julia Ling},
   month = {11},
   title = {Assessing the Frontier: Active Learning, Model Accuracy, and Multi-objective Materials Discovery and Optimization},
   url = {http://arxiv.org/abs/1911.03224},
   year = {2019},
}
@inproceedings{Ishibuchi2015,
   abstract = {In this paper, we propose the use of modified distance calculation in generational distance (GD) and inverted generational distance (IGD). These performance indicators evaluate the quality of an obtained solution set in comparison with a pre-specified reference point set. Both indicators are based on the distance between a solution and a reference point. The Euclidean distance in an objective space is usually used for distance calculation. Our idea is to take into account the dominance relation between a solution and a reference point when we calculate their distance. If a solution is dominated by a reference point, the Euclidean distance is used for their distance calculation with no modification. However, if they are non-dominated with each other, we calculate the minimum distance from the reference point to the dominated region by the solution. This distance can be viewed as an amount of the inferiority of the solution (i.e., the insufficiency of its objective values) in comparison with the reference point. We demonstrate using simple examples that some Pareto non-compliant results of GD and IGD are resolved by the modified distance calculation. We also show that IGD with the modified distance calculation is weakly Pareto compliant whereas the original IGD is Pareto non-compliant.},
   author = {Hisao Ishibuchi and  Hiroyuki Masuda and  Yuki Tanigaki and  Yusuke Nojima},
   city = {Cham},
   isbn = {978-3-319-15892-1},
   journal = {Evolutionary Multi-Criterion Optimization},
   pages = {110-125},
   publisher = {Springer International Publishing},
   title = {Modified Distance Calculation in Generational Distance and Inverted Generational Distance},
   year = {2015},
}
@inproceedings{Coello2004,
   abstract = {In this paper, we present a parallel version of a multi-objective evolutionary algorithm that incorporates some coevolutionary concepts. Such an algorithm was previosly developed by the authors. Two approaches were adopted to parallelize our algorithm (both of them based on a master-slave scheme): one uses Pthreads (shared memory) and the other one uses MPI (distributed memory). We conduct a small comparative study to analyze the impact that the parallelization has on performance. Our results indicate that both parallel versions produce important improvements in the execution times of the algorithm (with respect to the serial version) while keeping the quality of the results obtained.},
   author = {Carlos A. Margarita Coello Coello and Sierra Reyes},
   city = {Berlin, Heidelberg},
   isbn = {978-3-540-24694-7},
   journal = {MICAI 2004: Advances in Artificial Intelligence},
   pages = {688-697},
   publisher = {Springer Berlin Heidelberg},
   title = {A Study of the Parallelization of a Coevolutionary Multi-objective Evolutionary Algorithm},
   year = {2004},
}
@article{Veldhuizen2000,
   abstract = { Solving optimization problems with multiple (often conflicting) objectives is, generally, a very difficult goal. Evolutionary algorithms (EAs) were initially extended and applied during the mid-eighties in an attempt to stochastically solve problems of this generic class. During the past decade, a variety of multiobjective EA (MOEA) techniques have been proposed and applied to many scientific and engineering applications. Our discussion's intent is to rigorously define multiobjective optimization problems and certain related concepts, present an MOEA classification scheme, and evaluate the variety of contemporary MOEAs. Current MOEA theoretical developments are evaluated; specific topics addressed include fitness functions, Pareto ranking, niching, fitness sharing, mating restriction, and secondary populations. Since the development and application of MOEAs is a dynamic and rapidly growing activity, we focus on key analytical insights based upon critical MOEA evaluation of current research and applications. Recommended MOEA designs are presented, along with conclusions and recommendations for future work. },
   author = {David A Van Veldhuizen and Gary B Lamont},
   doi = {10.1162/106365600568158},
   issue = {2},
   journal = {Evolutionary Computation},
   pages = {125-147},
   title = {Multiobjective Evolutionary Algorithms: Analyzing the State-of-the-Art},
   volume = {8},
   url = {https://doi.org/10.1162/106365600568158},
   year = {2000},
}
@inproceedings{Deb2000,
   abstract = {Multi-objective evolutionary algorithms which use non-dominated sorting and sharing have been mainly criticized for their (i) O(MN3) computational complexity (where M is the number of objectives and N is the population size), (ii) non-elitism approach, and (iii) the need for specifying a sharing parameter. In this paper, we suggest a non-dominated sorting based multi-objective evolutionary algorithm (we called it the Non-dominated Sorting GA-II or NSGA-II) which alleviates all the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN2) computational complexity is presented. Second, a selection operator is presented which creates a mating pool by combining the parent and child populations and selecting the best (with respect to fitness and spread) N solutions. Simulation results on five difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to PAES and SPEA—two other elitist multi-objective EAs which pay special attention towards creating a diverse Pareto-optimal front. Because of NSGA-II's low computational requirements, elitist approach, and parameter-less sharing approach, NSGA-II should find increasing applications in the years to come.},
   author = {Kalyanmoy Deb and  Samir Agrawal and  Amrit Pratap and  T Meyarivan},
   city = {Berlin, Heidelberg},
   isbn = {978-3-540-45356-7},
   journal = {Parallel Problem Solving from Nature PPSN VI},
   pages = {849-858},
   publisher = {Springer Berlin Heidelberg},
   title = {A Fast Elitist Non-dominated Sorting Genetic Algorithm for Multi-objective Optimization: NSGA-II},
   year = {2000},
}
@article{Kaliszewski1987,
   abstract = {We show how to determine nondominated criterion vectors (and then nondominated solutions, if necessary) by a modified weighted Tchebycheff metric in cases when sets of all criterion vectors are finite or polyhedral.},
   author = {Ignacy Kaliszewski},
   doi = {https://doi.org/10.1016/0305-0548(87)90069-4},
   issn = {0305-0548},
   issue = {4},
   journal = {Computers & Operations Research},
   pages = {315 - 323},
   title = {A modified weighted tchebycheff metric for multiple objective programming},
   volume = {14},
   url = {http://www.sciencedirect.com/science/article/pii/0305054887900694},
   year = {1987},
}
@article{Steuer1989,
   author = {Ralph E. Steuer},
   doi = {10.1002/oca.4660100109},
   issue = {1},
   journal = {Optimal Control Applications and Methods},
   pages = {89-90},
   title = {Multiple criteria optimization; theory, computation, and application},
   volume = {10},
   url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/oca.4660100109},
   year = {1989},
}
@article{Keane2006,
   author = {A J Keane},
   doi = {10.2514/1.16875},
   issue = {4},
   journal = {AIAA Journal},
   pages = {879-891},
   title = {Statistical Improvement Criteria for Use in Multiobjective Design Optimization},
   volume = {44},
   url = {https://doi.org/10.2514/1.16875},
   year = {2006},
}
@inproceedings{Yang2017,
   abstract = {The Expected Hypervolume Improvement (EHVI) is a frequently used infill criterion in surrogate-assisted multi-criterion optimization. It needs to be frequently called during the execution of such algorithms. Despite recent advances in improving computational efficiency, its running time for three or more objectives has remained in $$O(n^d)$$for $$d\ge 3$$, where d is the number of objective functions and n is the size of the incumbent Pareto-front approximation. This paper proposes a new integration scheme, which makes it possible to compute the EHVI in $$\varTheta (n \log n)$$optimal time for the important three-objective case ($$d=3$$). The new scheme allows for a generalization to higher dimensions and for computing the Probability of Improvement (PoI) integral efficiently. It is shown, both theoretically and empirically, that the hidden constant in the asymptotic notation is small. Empirical speed comparisons were designed between the C++ implementations of the new algorithm (which will be in the public domain) and those recently published by competitors, on randomly-generated non-dominated fronts of size 10, 100, and 1000. The experiments include the analysis of batch computations, in which only the parameters of the probability distribution change but the incumbent Pareto-front approximation stays the same. Experimental results show that the new algorithm is always faster than the other algorithms, sometimes over $$10^4$$times faster.},
   author = {Kaifeng Yang and Michael Emmerich and André Deutz and Carlos M. Fonseca},
   city = {Cham},
   isbn = {978-3-319-54157-0},
   journal = {Evolutionary Multi-Criterion Optimization},
   pages = {685-700},
   publisher = {Springer International Publishing},
   title = {Computing 3-D Expected Hypervolume Improvement and Related Integrals in Asymptotically Optimal Time},
   year = {2017},
}
@book_section{Emmerich2016,
   abstract = {This chapter discusses a generalization of the expected improvement used in Bayesian global optimization to the multicriteria optimization domain, where the goal is to find an approximation to the Pareto front. The expected hypervolume improvement (EHVI) measures improvement as the gain in dominated hypervolume relative to a given approximation to the Pareto front. We will review known properties of the EHVI, applications in practice and propose a new exact algorithm for computing EHVI. The new algorithm has asymptotically optimal time complexity O(nlogn). This improves existing computation schemes by a factor of n∕logn. It shows that this measure, at least for a small number of objective functions, is as fast as other simpler measures of multicriteria expected improvement that were considered in recent years.},
   author = {Michael Emmerich and Kaifeng Yang and André Deutz and Hao Wang and Carlos M. Fonseca},
   city = {Cham},
   doi = {10.1007/978-3-319-29975-4_12},
   isbn = {978-3-319-29975-4},
   journal = {Advances in Stochastic and Deterministic Global Optimization},
   pages = {229-242},
   publisher = {Springer International Publishing},
   title = {A Multicriteria Generalization of Bayesian Global Optimization},
   url = {https://doi.org/10.1007/978-3-319-29975-4_12},
   year = {2016},
}
@inproceedings{Hupkens2015,
   abstract = {This paper is about computing the expected improvement of the hypervolume indicator given a Pareto front approximation and a predictive multivariate Gaussian distribution of a new candidate point. It is frequently used as an infill or prescreening criterion in multiobjective optimization with expensive function evaluations where predictions are provided by Kriging or Gaussian process surrogate models. The expected hypervolume improvement has good properties as an infill criterion, but exact algorithms for its computation have so far been very time consuming even for the two and three objective case. This paper introduces faster exact algorithms for computing the expected hypervolume improvement for independent Gaussian distributions. A new general computation scheme is introduced and a lower bound for the time complexity. By providing new algorithms, upper bounds for the time complexity for problems with two as well as three objectives are improved. For the 2-D case the time complexity bound is reduced from previously $$O(n^3 \log n)$$to $$O(n^2)$$. For the 3-D case the new upper bound of $$O(n^3)$$is established; previously $$O(n^4 \log n)$$. It is also shown how an efficient implementation of these new algorithms can lead to a further reduction of running time. Moreover it is shown how to process batches of multiple predictive distributions efficiently. The theoretical analysis is complemented by empirical speed comparisons of C++ implementations of the new algorithms to existing implementations of other exact algorithms.},
   author = {Iris Hupkens and André Deutz and Kaifeng Yang and Michael Emmerich},
   city = {Cham},
   isbn = {978-3-319-15892-1},
   journal = {Evolutionary Multi-Criterion Optimization},
   pages = {65-79},
   publisher = {Springer International Publishing},
   title = {Faster Exact Algorithms for Computing Expected Hypervolume Improvement},
   year = {2015},
}
@article{Couckuyt2014,
   abstract = {The use of surrogate based optimization (SBO) is widely spread in engineering design to reduce the number of computational expensive simulations. However, “real-world” problems often consist of multiple, conflicting objectives leading to a set of competitive solutions (the Pareto front). The objectives are often aggregated into a single cost function to reduce the computational cost, though a better approach is to use multiobjective optimization methods to directly identify a set of Pareto-optimal solutions, which can be used by the designer to make more efficient design decisions (instead of weighting and aggregating the costs upfront). Most of the work in multiobjective optimization is focused on multiobjective evolutionary algorithms (MOEAs). While MOEAs are well-suited to handle large, intractable design spaces, they typically require thousands of expensive simulations, which is prohibitively expensive for the problems under study. Therefore, the use of surrogate models in multiobjective optimization, denoted as multiobjective surrogate-based optimization, may prove to be even more worthwhile than SBO methods to expedite the optimization of computational expensive systems. In this paper, the authors propose the efficient multiobjective optimization (EMO) algorithm which uses Kriging models and multiobjective versions of the probability of improvement and expected improvement criteria to identify the Pareto front with a minimal number of expensive simulations. The EMO algorithm is applied on multiple standard benchmark problems and compared against the well-known NSGA-II, SPEA2 and SMS-EMOA multiobjective optimization methods.},
   author = {Ivo Couckuyt and Dirk Deschrijver and Tom Dhaene},
   doi = {10.1007/s10898-013-0118-2},
   issn = {1573-2916},
   issue = {3},
   journal = {Journal of Global Optimization},
   pages = {575-594},
   title = {Fast calculation of multiobjective probability of improvement and expected improvement criteria for Pareto optimization},
   volume = {60},
   url = {https://doi.org/10.1007/s10898-013-0118-2},
   year = {2014},
}
@article{Yang2019,
   abstract = {In the field of multi-objective optimization algorithms, multi-objective Bayesian Global Optimization (MOBGO) is an important branch, in addition to evolutionary multi-objective optimization algorithms. MOBGO utilizes Gaussian Process models learned from previous objective function evaluations to decide the next evaluation site by maximizing or minimizing an infill criterion. A commonly used criterion in MOBGO is the Expected Hypervolume Improvement (EHVI), which shows a good performance on a wide range of problems, with respect to exploration and exploitation. However, so far, it has been a challenge to calculate exact EHVI values efficiently. This paper proposes an efficient algorithm for the exact calculation of the EHVI for in a generic case. This efficient algorithm is based on partitioning the integration volume into a set of axis-parallel slices. Theoretically, the upper bound time complexities can be improved from previously $$O (n^2)$$O(n2)and $$O(n^3)$$O(n3), for two- and three-objective problems respectively, to $$\varTheta (n\log n)$$Θ(nlogn), which is asymptotically optimal. This article generalizes the scheme in higher dimensional cases by utilizing a new hyperbox decomposition technique, which is proposed by Dächert et al. (Eur J Oper Res 260(3):841–855, 2017). It also utilizes a generalization of the multilayered integration scheme that scales linearly in the number of hyperboxes of the decomposition. The speed comparison shows that the proposed algorithm in this paper significantly reduces computation time. Finally, this decomposition technique is applied in the calculation of the Probability of Improvement (PoI).},
   author = {Kaifeng Yang and Michael Emmerich and André Deutz and Thomas Bäck},
   doi = {10.1007/s10898-019-00798-7},
   issn = {1573-2916},
   issue = {1},
   journal = {Journal of Global Optimization},
   pages = {3-34},
   title = {Efficient computation of expected hypervolume improvement using box decomposition algorithms},
   volume = {75},
   url = {https://doi.org/10.1007/s10898-019-00798-7},
   year = {2019},
}
@article{Picheny2015,
   abstract = {Optimization of expensive computer models with the help of Gaussian process emulators is now commonplace. However, when several (competing) objectives are considered, choosing an appropriate sampling strategy remains an open question. We present here a new algorithm based on stepwise uncertainty reduction principles. Optimization is seen as a sequential reduction of the volume of the excursion sets below the current best solutions (Pareto set), and our sampling strategy chooses the points that give the highest expected reduction. The method is tested on several numerical examples and on an agronomy problem, showing that it provides an efficient trade-off between exploration and intensification.},
   author = {Victor Picheny},
   doi = {10.1007/s11222-014-9477-x},
   issn = {1573-1375},
   issue = {6},
   journal = {Statistics and Computing},
   pages = {1265-1280},
   title = {Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction},
   volume = {25},
   url = {https://doi.org/10.1007/s11222-014-9477-x},
   year = {2015},
}
@article{Qi2020,
   title = "An adaptive penalty-based boundary intersection method for many-objective optimization problem",
   journal = "Information Sciences",
   volume = "509",
   pages = "356 - 375",
   year = "2020",
   issn = "0020-0255",
   doi = "https://doi.org/10.1016/j.ins.2019.03.040",
   url = "http://www.sciencedirect.com/science/article/pii/S0020025519302439",
   author = "Yutao Qi and Dazhuang Liu and Xiaodong Li and Jiaojiao Lei and Xiaoying Xu and Qiguang Miao",
   keywords = "Many-objective optimization, Multi-objective evolutionary algorithm based on decomposition, Penalty-based boundary intersection, Adaptive penalty scheme",
   abstract = "Compared with domination-based methods, the multi-objective evolutionary algorithm based on decomposition (MOEA/D) is less prone to the difficulty caused by an increase in the number of objectives. It is a promising algorithmic framework for solving many-objective optimization problems (MaOPs). In MOEA/D, the target MaOP is decomposed into a set of single-objective problems by using a scalarizing function with evenly specified weight vectors. Among the available scalarizing functions, penalty-based boundary intersection (PBI) with an appropriate penalty parameter is known to perform well. However, its performance is heavily influenced by the setting of the penalty factor (θ), which can take a value from zero to +∞. A limited amount of work has thus far considered the choice of an appropriate value of θ. This paper presents a comprehensive experimental study on WFG and WFG-extend problems featuring two to 15 objectives. A range of values of θ is investigated to understand its influence on the performance of the PBI-based MOEA/D (MOEA/D-PBI). Based on the observations, the range of values of θ are divided into three sub-regions, and a two-stage adaptive penalty scheme is proposed to adaptively choose an appropriate value from 0.001 to 8000 during an optimization run. The results of experiments show that, the robustness of MOEA/D-PBI can be significantly enhanced using the proposed scheme."
}
@article{Ming2017,
   title = "Pareto adaptive penalty-based boundary intersection method for multi-objective optimization",
   journal = "Information Sciences",
   volume = "414",
   pages = "158 - 174",
   year = "2017",
   issn = "0020-0255",
   doi = "https://doi.org/10.1016/j.ins.2017.05.012",
   url = "http://www.sciencedirect.com/science/article/pii/S0020025516320692",
   author = "Mengjun Ming and Rui Wang and Yabing Zha and Tao Zhang",
   keywords = "Multi-objective evolutionary algorithms, Scalarizing method, Pareto adaptive PBI method, Hybrid renewable energy system",
   abstract = "Penalty-based boundary intersection (PBI) method is a frequently used scalarizing method in decomposition based multi-objective evolutionary algorithms (MOEAs). It works well when a proper penalty value is provided, however, the determination of a suitable penalty value depends on the problem itself, more precisely, the Pareto optimal front (PF) shape. As the penalty value increases, the PBI method becomes less effective in terms of convergence, but is more capable of handling various PF shapes. In this study, a simple yet effective method called Pareto adaptive PBI (PaP) is proposed by which a suitable penalty value can be adaptively identified, which therefore can maintain fast convergence speed, meanwhile, leading to a good approximation of the PF. The PaP strategy integrated into the state-of-the-art decomposition algorithm, MOEA/D, denoted as MOEA/D-PaP, is examined on a set of multi-objective benchmarks with different PF shapes. Experimental results show that the PaP strategy is more effective than the weighted sum, the weighted Tchebycheff and the PBI method with (representative) fixed penalty values in general. In addition, the MOEA/D-PaP is examined on a real-world problem – multi-objective optimization of a hybrid renewable energy system whose PF is unknown. The outcome of the experiment further confirms its feasibility and superiority."
}